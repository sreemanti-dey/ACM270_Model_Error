{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Get Trajectory graphs"
      ],
      "metadata": {
        "id": "EmX3qgSvHRe-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "t4kD0eduC80W"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "!pip install filterpy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "from filterpy.kalman import EnsembleKalmanFilter as EnKF\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.integrate as integrate\n",
        "from scipy.interpolate import griddata\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "import optax\n",
        "from jax import jit, random, lax\n",
        "from jax.scipy.linalg import sqrtm\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import integrate\n",
        "from jax.tree_util import Partial\n",
        "from functools import partial\n",
        "\n",
        "if os.path.isdir('./ACM270_Model_Error/') == False:\n",
        "    ! git clone https://github.com/sreemanti-dey/ACM270_Model_Error.git\n",
        "sys.path.append('./ACM270_Model_Error/')\n",
        "\n",
        "! cd ACM270_Model_Error\n",
        "\n",
        "\"\"\"# True Trajectory and Noisy Observations with 2-Scale Lorenz96\"\"\"\n",
        "\n",
        "# parameters for two-scale L96\n",
        "K = 36                      # number of large scale vars\n",
        "J = 10                      # number of small scale vars per large var\n",
        "h = 0.25                   # part of coupling\n",
        "c = 10                     # part of coupling\n",
        "b = 10                     # part of coupling\n",
        "F = 10                     # forcing\n",
        "\n",
        "dt = 0.1                  # time step\n",
        "noise_const = 0.1\n",
        "num_steps = 200\n",
        "time_steps = num_steps\n",
        "\n",
        "num_steps = int(num_steps * (0.05 / dt))\n",
        "time_steps = num_steps\n",
        "\n",
        "@jit\n",
        "def L96_2(xy):\n",
        "    x = xy[0:K]\n",
        "    y = xy[K:].reshape(K, J)\n",
        "\n",
        "    dx = jnp.zeros(K)\n",
        "    dy = jnp.zeros((K, J))\n",
        "\n",
        "    for k in range(K):\n",
        "        dxdt = -1 * x[k - 1] * (x[k - 2] - x[(k + 1) % K]) - x[k] + F - (h * c / b) * jnp.sum(y[k])\n",
        "        dx = dx.at[k].set(dxdt)\n",
        "\n",
        "        for j in range(J):\n",
        "            dydt = -1 * c * b * y[k, (j + 1) % J] * (y[k, (j + 2) % J] - y[k, j - 1]) - c * y[k, j] + (h * c / b) * x[k]\n",
        "            dy = dy.at[k, j].set(dydt)\n",
        "\n",
        "    return jnp.concatenate([dx, dy.flatten()])\n",
        "\n",
        "@jit\n",
        "def rk4_step_lorenz96_2(x):\n",
        "    f = lambda y: L96_2(y)\n",
        "    k1 = dt * f(x)\n",
        "    k2 = dt * f(x + k1/2)\n",
        "    k3 = dt * f(x + k2/2)\n",
        "    k4 = dt * f(x + k3)\n",
        "    return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "keys = iter(random.split(random.PRNGKey(0), 10))\n",
        "key = random.PRNGKey(0)\n",
        "# randomized starting point for large scale, 0 for small scale\n",
        "x0 = np.linspace(0, 1, K)  # np.random.rand(K)\n",
        "y0 = np.zeros((K, J))\n",
        "xy0 = np.concatenate([x0, y0.flatten()])\n",
        "\n",
        "rk4_step_lorenz96_2(xy0)\n",
        "\n",
        "trajectory = jnp.zeros((time_steps, len(xy0)))\n",
        "noisy_obs = jnp.zeros((time_steps, len(xy0)))\n",
        "noise_covar = jnp.eye(len(xy0)) * noise_const\n",
        "\n",
        "xy = xy0\n",
        "for i in tqdm(range(time_steps)):\n",
        "    xy = rk4_step_lorenz96_2(xy)\n",
        "    trajectory = trajectory.at[i].set(xy)\n",
        "    # Add noise to the observations\n",
        "    noise = random.multivariate_normal(key, jnp.zeros(len(xy0)), noise_covar)\n",
        "    noisy_obs = noisy_obs.at[i].set(xy + noise)\n",
        "    key, _ = random.split(key)  # Update key for the next iteration\n",
        "\n",
        "\"\"\"## True Trajectory\n",
        "\n",
        "## Noisy Observations\n",
        "\"\"\"\n",
        "\n",
        "true_states = trajectory\n",
        "\n",
        "\"\"\"# EnKF for 1-Scale Assimilation\"\"\"\n",
        "\n",
        "@jit\n",
        "def rk4_step_lorenz96_1(x):\n",
        "    f = lambda y: (jnp.roll(y, 1) - jnp.roll(y, -2)) * jnp.roll(y, -1) - y + F\n",
        "    k1 = dt * f(x)\n",
        "    k2 = dt * f(x + k1/2)\n",
        "    k3 = dt * f(x + k2/2)\n",
        "    k4 = dt * f(x + k3)\n",
        "    return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "lorenz1 = Partial(rk4_step_lorenz96_1)\n",
        "lorenz2 = Partial(rk4_step_lorenz96_2)\n",
        "\n",
        "@jit\n",
        "def ledoit_wolf(P, shrinkage):\n",
        "    return (1 - shrinkage) * P + shrinkage * jnp.trace(P) / P.shape[0] * jnp.eye(P.shape[0])\n",
        "\n",
        "@jit\n",
        "def ensrf_step(ensemble, y, H, Q, R, key, inflation = 1.2):\n",
        "    n_ensemble = ensemble.shape[1]\n",
        "    x_m = jnp.mean(ensemble, axis=1)\n",
        "    A = ensemble - x_m.reshape((-1, 1))\n",
        "    C_pred = (A @ A.T) / (n_ensemble - 1) + Q\n",
        "    C_pred = ledoit_wolf(C_pred, noise_const)\n",
        "    A = A * inflation\n",
        "    P =  (A @ A.T) / (n_ensemble - 1) + Q\n",
        "    K = P @ H.T @ jnp.linalg.inv(H @ P @ H.T + R)\n",
        "    x_m += K @ (y - H @ x_m)\n",
        "    M_sqrt = sqrt_m(jnp.eye(x_m.shape[0]) - K @ H)\n",
        "    updated_A = M_sqrt @ A\n",
        "    updated_ensemble = x_m.reshape((-1, 1)) + updated_A\n",
        "    updated_P = (updated_A @ updated_A.T) / (n_ensemble - 1)\n",
        "    updated_P = ledoit_wolf(updated_P, noise_const)\n",
        "\n",
        "    ensemble = ensemble.astype(jnp.float32)\n",
        "    C_pred = C_pred.astype(jnp.float32)\n",
        "    updated_ensemble = updated_ensemble.astype(jnp.float32)\n",
        "    updated_P = updated_P.astype(jnp.float32)\n",
        "    return ensemble, C_pred, updated_ensemble, updated_P\n",
        "\n",
        "@jit\n",
        "def sqrt_m(M):\n",
        "    eigenvalues, eigenvectors = jnp.linalg.eigh(M)\n",
        "    inv_sqrt_eigenvalues = jnp.sqrt(eigenvalues)\n",
        "    Lambda_inv_sqrt = jnp.diag(inv_sqrt_eigenvalues)\n",
        "    M_sqrt = eigenvectors @ Lambda_inv_sqrt @ eigenvectors.T\n",
        "    return M_sqrt.real\n",
        "\n",
        "@partial(jit, static_argnums=(3))\n",
        "def ensrf_steps(state_transition_function, n_ensemble, ensemble_init, num_steps, observations, observation_interval, H, Q, R, key):\n",
        "    model_vmap = jax.vmap(lambda v: state_transition_function(v), in_axes=1, out_axes=1)\n",
        "    key, *subkeys = random.split(key, num=num_steps + 1)\n",
        "    subkeys = jnp.array(subkeys)\n",
        "\n",
        "    def inner(carry, t):\n",
        "        ensemble, covar = carry\n",
        "        ensemble_predicted = model_vmap(ensemble)\n",
        "        _, C_forecast, ensemble_analysis, C_analysis = ensrf_step(ensemble_predicted, observations[t, :], H, Q, R, subkeys[t])\n",
        "        return (ensemble_analysis, C_analysis), (ensemble_predicted, C_forecast, ensemble_analysis, C_analysis)\n",
        "\n",
        "    n = len(Q[0])\n",
        "    covariance_init = jnp.zeros((n, n))\n",
        "    _, (ensemble_forecast, C_forecast, ensemble_analysis, C_analysis) = jax.lax.scan(inner, (ensemble_init, covariance_init), jnp.arange(num_steps))\n",
        "\n",
        "    return ensemble_forecast, C_forecast, ensemble_analysis, C_analysis\n",
        "\n",
        "class IncrementCorrectionModel(nn.Module):\n",
        "    features: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        x = nn.Dense(self.features)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Dense(self.features)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Dense(self.features)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Dense(x.shape[-1])(x)  # Output layer should match input dimension\n",
        "        return x\n",
        "\n",
        "def create_model(key, input_shape, features):\n",
        "    model = IncrementCorrectionModel(features)\n",
        "    params = model.init(key, jnp.ones(input_shape))['params']\n",
        "    return model, params\n",
        "\n",
        "def loss_fn(params, apply_fn, x, y):\n",
        "    predictions = apply_fn({'params': params}, x)\n",
        "    loss = jnp.mean((predictions - y) ** 2)\n",
        "    return loss\n",
        "\n",
        "@jax.jit\n",
        "def train_step(state, forecast_states, increments):\n",
        "    def loss_fn_wrapper(params):\n",
        "        return loss_fn(params, state.apply_fn, forecast_states, increments)\n",
        "\n",
        "    grads = jax.grad(loss_fn_wrapper)(state.params)\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "    return state\n",
        "\n",
        "def train_nn(state, forecast_states, analysis_states, num_epochs=10):\n",
        "    increments = analysis_states - forecast_states\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        state = train_step(state, forecast_states, increments)\n",
        "        current_loss = loss_fn(state.params, state.apply_fn, forecast_states, increments)\n",
        "        print(f'Epoch {epoch+1}, Loss: {current_loss}')\n",
        "\n",
        "    return state\n",
        "\n",
        "Q = noise_const * jnp.eye(K)\n",
        "H = jnp.eye(K)\n",
        "R = jnp.eye(K) * noise_const\n",
        "n_ensemble = 10\n",
        "num_steps = time_steps\n",
        "#the ensrf (ENKF) will run single scale Lorenz on the first K variables\n",
        "observations = noisy_obs[:,:K]\n",
        "initial_state = np.zeros((1, K))\n",
        "ensemble_init = random.multivariate_normal(key, initial_state, Q, (n_ensemble,)).T\n",
        "ensemble_forecast, C_forecast, ensemble_analysis, C_analysis = ensrf_steps(lorenz1, n_ensemble, ensemble_init, time_steps, observations, 1, H, Q, R, key)\n",
        "\n",
        "time_steps = ensemble_forecast.shape[0]\n",
        "time = jnp.arange(time_steps)\n",
        "\n",
        "forecast_means = jnp.mean(ensemble_forecast, axis=2)\n",
        "analysis_means = jnp.mean(ensemble_analysis, axis=2)\n",
        "\n",
        "file = f\"ACM270_Model_Error/long_training_data_noise_{noise_const}_dt_{dt}.npz\"\n",
        "data = np.load(file)\n",
        "forecast_state = data[\"forecast\"]\n",
        "analysis_state = data[\"analysis\"]\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "input_shape = (K,)\n",
        "features = K\n",
        "model, params = create_model(key, input_shape, features)\n",
        "\n",
        "learning_rate = 1e-3\n",
        "optimizer = optax.adam(learning_rate)\n",
        "state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=optimizer)\n",
        "\n",
        "num_epochs = 15\n",
        "_,_,n = forecast_state.shape\n",
        "for i in range(n):\n",
        "  forecast_means = forecast_state[:,:,i]\n",
        "  analysis_means = analysis_state[:,:,i]\n",
        "  state = train_nn(state, forecast_means, analysis_means, num_epochs=num_epochs)\n",
        "\n",
        "#@partial(jax.jit, static_argnums=(3))\n",
        "def ensrf_steps_nn(state_transition_function, n_ensemble, ensemble_init, num_steps, observations, observation_interval, H, Q, R, key, nn_params, model):\n",
        "    def corrected_state_transition(v):\n",
        "        transition = state_transition_function(v)\n",
        "        correction = model.apply({'params': nn_params}, transition)\n",
        "        return transition + correction\n",
        "\n",
        "    model_vmap = jax.vmap(corrected_state_transition, in_axes=1, out_axes=1)\n",
        "    key, *subkeys = jax.random.split(key, num=num_steps + 1)\n",
        "    subkeys = jnp.array(subkeys)\n",
        "\n",
        "    def inner(carry, t):\n",
        "        ensemble, covar = carry\n",
        "        ensemble_predicted = model_vmap(ensemble)\n",
        "        _, C_forecast, ensemble_analysis, C_analysis = ensrf_step(ensemble_predicted, observations[t, :], H, Q, R, subkeys[t])\n",
        "        return (ensemble_analysis, C_analysis), (ensemble_predicted, C_forecast, ensemble_analysis, C_analysis)\n",
        "\n",
        "    n = len(Q[0])\n",
        "    covariance_init = jnp.zeros((n, n))\n",
        "    _, (ensemble_forecast, C_forecast, ensemble_analysis, C_analysis) = jax.lax.scan(inner, (ensemble_init, covariance_init), jnp.arange(num_steps))\n",
        "\n",
        "    return ensemble_forecast, C_forecast, ensemble_analysis, C_analysis\n",
        "\n",
        "nn_params = state.params\n",
        "ensemble_forecast_NN, C_forecast_NN, ensemble_analysis_NN, C_analysis_NN = ensrf_steps_nn(\n",
        "    lorenz1,\n",
        "    n_ensemble,\n",
        "    ensemble_init,\n",
        "    time_steps,\n",
        "    observations,\n",
        "    1,\n",
        "    H,\n",
        "    Q,\n",
        "    R,\n",
        "    key,\n",
        "    nn_params,\n",
        "    model\n",
        ")\n",
        "\n",
        "ensemble_forecast, C_forecast, ensemble_analysis, C_analysis = ensrf_steps(\n",
        "    lorenz1,\n",
        "    n_ensemble,\n",
        "    ensemble_init,\n",
        "    time_steps,\n",
        "    observations,\n",
        "    1,\n",
        "    H,\n",
        "    Q,\n",
        "    R,\n",
        "    key\n",
        ")\n",
        "\n",
        "time_steps = ensemble_forecast.shape[0]\n",
        "time = jnp.arange(time_steps)\n",
        "\n",
        "true_states = trajectory\n",
        "forecast_means = jnp.mean(ensemble_forecast, axis=2)\n",
        "analysis_means = jnp.mean(ensemble_analysis, axis=2)\n",
        "\n",
        "forecast_means_NN = jnp.mean(ensemble_forecast_NN, axis=2)\n",
        "analysis_means_NN = jnp.mean(ensemble_analysis_NN, axis=2)\n",
        "\n",
        "model_error = observations - forecast_means\n",
        "NRMSE_fm = np.dot(model_error.flatten(), model_error.flatten()) / np.dot(observations.flatten(), observations.flatten())\n",
        "model_error = observations - analysis_means\n",
        "NRMSE_as = np.dot(model_error.flatten(), model_error.flatten()) / np.dot(observations.flatten(), observations.flatten())\n",
        "model_error = observations - forecast_means_NN\n",
        "NRMSE_fm_NN = np.dot(model_error.flatten(), model_error.flatten()) / np.dot(observations.flatten(), observations.flatten())\n",
        "model_error = observations - analysis_means_NN\n",
        "NRMSE_as_NN = np.dot(model_error.flatten(), model_error.flatten()) / np.dot(observations.flatten(), observations.flatten())\n",
        "\n",
        "fontsize = 25\n",
        "res = 500\n",
        "\n",
        "time = np.arange(0, time_steps)*dt\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "i = 0  # Index of the state variable to plot\n",
        "plt.plot(time, true_states[:, i], label=f\"True state {i+1}\", linestyle=\"-\", marker=\"o\",color='k', linewidth=2.5,markersize=7)\n",
        "plt.plot(time, forecast_means[:, i], label=f\"Forecast mean - {i+1}\", linestyle=\"--\", marker=\"x\",color='b', linewidth=2.5,markersize=7)\n",
        "plt.plot(time, analysis_means[:, i], label=f\"Analysis mean - {i+1}\", linestyle=\":\", marker=\"d\",color='green', linewidth=2.5,markersize=7)\n",
        "plt.scatter(time, observations[:, i], label=f\"Observations - {i+1}\", marker=\"s\",color='gray')\n",
        "\n",
        "plt.xlabel(\"Time\",fontsize=fontsize)\n",
        "plt.ylabel(\"State values\",fontsize=fontsize)\n",
        "plt.title(\"EnKF prediction with True State and Observations\",fontsize=fontsize)\n",
        "plt.legend(fontsize=fontsize/1.5)\n",
        "plt.grid(True)\n",
        "plt.xticks(fontsize=fontsize / 1.25)\n",
        "plt.yticks(fontsize=fontsize / 1.25)\n",
        "plt.savefig(f'uncorrected_noise_{noise_const}_dt_{dt}.png', bbox_inches=\"tight\", dpi=res)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "i = 0  # Index of the state variable to plot\n",
        "plt.plot(time, true_states[:, i], label=f\"True state {i+1}\", linestyle=\"-\", marker=\"o\",color='k', linewidth=2.5,markersize=7)\n",
        "plt.plot(time, forecast_means_NN[:, i], label=f\"Forecast mean - {i+1}\", linestyle=\"--\", marker=\"x\",color='b', linewidth=2.5,markersize=7)\n",
        "plt.plot(time, analysis_means_NN[:, i], label=f\"Analysis mean - {i+1}\", linestyle=\":\", marker=\"d\",color='green', linewidth=2.5,markersize=7)\n",
        "plt.scatter(time, observations[:, i], label=f\"Observations {i+1}\", marker=\"s\",color='gray')\n",
        "\n",
        "plt.xlabel(\"Time\",fontsize=fontsize)\n",
        "plt.ylabel(\"State values\",fontsize=fontsize)\n",
        "plt.title(\"Corrected EnKF prediction with True State and Observations\",fontsize=fontsize)\n",
        "plt.legend(fontsize=fontsize/1.5)\n",
        "plt.grid(True)\n",
        "plt.xticks(fontsize=fontsize / 1.25)\n",
        "plt.yticks(fontsize=fontsize / 1.25)\n",
        "plt.savefig(f'corrected_noise_{noise_const}_dt_{dt}.png', bbox_inches=\"tight\", dpi=res)\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "i = 0  # Index of the state variable to plot\n",
        "plt.plot(time, analysis_means[:, i], label=f\"Forecast mean - {i+1}\", linestyle=\"--\", marker=\"x\",color='b', linewidth=2.5,markersize=7)\n",
        "plt.plot(time, forecast_means_NN[:, i], label=f\"Analysis mean - {i+1}\", linestyle=\":\", marker=\"d\",color='green', linewidth=2.5,markersize=7)\n",
        "\n",
        "plt.xlabel(\"Time\",fontsize=fontsize)\n",
        "plt.ylabel(\"State values\",fontsize=fontsize)\n",
        "plt.title(\"EnKF analysis and NN prediction\",fontsize=fontsize)\n",
        "plt.legend(fontsize=fontsize/1.5)\n",
        "plt.grid(True)\n",
        "plt.xticks(fontsize=fontsize / 1.25)\n",
        "plt.yticks(fontsize=fontsize / 1.25)\n",
        "plt.savefig(f'NN_noise_{noise_const}_dt_{dt}.png', bbox_inches=\"tight\", dpi=res)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MSE vs. dt/noise"
      ],
      "metadata": {
        "id": "yFodXwJCohST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "!pip install filterpy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "from filterpy.kalman import EnsembleKalmanFilter as EnKF\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.integrate as integrate\n",
        "from scipy.interpolate import griddata\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "import optax\n",
        "from jax import jit, random, lax\n",
        "from jax.scipy.linalg import sqrtm\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import integrate\n",
        "from jax.tree_util import Partial\n",
        "from functools import partial\n",
        "\n",
        "! rm -rf ACM270_Model_Error\n",
        "# if os.path.isdir('./ACM270_Model_Error/') == False:\n",
        "! git clone https://github.com/sreemanti-dey/ACM270_Model_Error.git\n",
        "sys.path.append('./ACM270_Model_Error/')\n",
        "\n",
        "! cd ACM270_Model_Error\n",
        "\n",
        "\"\"\"# True Trajectory and Noisy Observations with 2-Scale Lorenz96\"\"\"\n",
        "\n",
        "noise_consts = [0.1, 0.5, 1, 5]\n",
        "dts = [0.01, 0.05, 0.1]\n",
        "\n",
        "full_NRMSE_as = np.zeros((len(noise_consts),len(dts)))\n",
        "full_NRMSE_as_NN = np.zeros((len(noise_consts),len(dts)))\n",
        "full_NRMSE_fm = np.zeros((len(noise_consts),len(dts)))\n",
        "full_NRMSE_fm_NN = np.zeros((len(noise_consts),len(dts)))\n",
        "\n",
        "for idx_n, noise_const in enumerate(noise_consts):\n",
        "  for idx_dt, dt in enumerate(dts):\n",
        "    # parameters for two-scale L96\n",
        "    K = 36                      # number of large scale vars\n",
        "    J = 10                      # number of small scale vars per large var\n",
        "    h = 0.25                   # part of coupling\n",
        "    c = 10                     # part of coupling\n",
        "    b = 10                     # part of coupling\n",
        "    F = 10                     # forcing\n",
        "    # dt = 0.1                  # time step\n",
        "    # noise_const = 0.1\n",
        "    num_steps = 200\n",
        "    num_steps = int(num_steps * (0.05 / dt))\n",
        "    time_steps = num_steps\n",
        "\n",
        "    @jit\n",
        "    def L96_2(xy):\n",
        "        x = xy[0:K]\n",
        "        y = xy[K:].reshape(K, J)\n",
        "\n",
        "        dx = jnp.zeros(K)\n",
        "        dy = jnp.zeros((K, J))\n",
        "\n",
        "        for k in range(K):\n",
        "            dxdt = -1 * x[k - 1] * (x[k - 2] - x[(k + 1) % K]) - x[k] + F - (h * c / b) * jnp.sum(y[k])\n",
        "            dx = dx.at[k].set(dxdt)\n",
        "\n",
        "            for j in range(J):\n",
        "                dydt = -1 * c * b * y[k, (j + 1) % J] * (y[k, (j + 2) % J] - y[k, j - 1]) - c * y[k, j] + (h * c / b) * x[k]\n",
        "                dy = dy.at[k, j].set(dydt)\n",
        "\n",
        "        return jnp.concatenate([dx, dy.flatten()])\n",
        "\n",
        "    @jit\n",
        "    def rk4_step_lorenz96_2(x):\n",
        "        f = lambda y: L96_2(y)\n",
        "        k1 = dt * f(x)\n",
        "        k2 = dt * f(x + k1/2)\n",
        "        k3 = dt * f(x + k2/2)\n",
        "        k4 = dt * f(x + k3)\n",
        "        return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "    keys = iter(random.split(random.PRNGKey(0), 10))\n",
        "    key = random.PRNGKey(0)\n",
        "    # randomized starting point for large scale, 0 for small scale\n",
        "    x0 = np.linspace(0, 1, K)  # np.random.rand(K)\n",
        "    y0 = np.zeros((K, J))\n",
        "    xy0 = np.concatenate([x0, y0.flatten()])\n",
        "\n",
        "    rk4_step_lorenz96_2(xy0)\n",
        "\n",
        "    trajectory = jnp.zeros((time_steps, len(xy0)))\n",
        "    noisy_obs = jnp.zeros((time_steps, len(xy0)))\n",
        "    noise_covar = jnp.eye(len(xy0)) * noise_const\n",
        "\n",
        "    xy = xy0\n",
        "    for i in tqdm(range(time_steps)):\n",
        "        xy = rk4_step_lorenz96_2(xy)\n",
        "        trajectory = trajectory.at[i].set(xy)\n",
        "        # Add noise to the observations\n",
        "        noise = random.multivariate_normal(key, jnp.zeros(len(xy0)), noise_covar)\n",
        "        noisy_obs = noisy_obs.at[i].set(xy + noise)\n",
        "        key, _ = random.split(key)  # Update key for the next iteration\n",
        "\n",
        "    \"\"\"## True Trajectory\n",
        "\n",
        "    ## Noisy Observations\n",
        "    \"\"\"\n",
        "\n",
        "    true_states = trajectory\n",
        "\n",
        "    \"\"\"# EnKF for 1-Scale Assimilation\"\"\"\n",
        "\n",
        "    @jit\n",
        "    def rk4_step_lorenz96_1(x):\n",
        "        f = lambda y: (jnp.roll(y, 1) - jnp.roll(y, -2)) * jnp.roll(y, -1) - y + F\n",
        "        k1 = dt * f(x)\n",
        "        k2 = dt * f(x + k1/2)\n",
        "        k3 = dt * f(x + k2/2)\n",
        "        k4 = dt * f(x + k3)\n",
        "        return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "    lorenz1 = Partial(rk4_step_lorenz96_1)\n",
        "    lorenz2 = Partial(rk4_step_lorenz96_2)\n",
        "\n",
        "    @jit\n",
        "    def ledoit_wolf(P, shrinkage):\n",
        "        return (1 - shrinkage) * P + shrinkage * jnp.trace(P) / P.shape[0] * jnp.eye(P.shape[0])\n",
        "\n",
        "    @jit\n",
        "    def ensrf_step(ensemble, y, H, Q, R, key, inflation = 1.2):\n",
        "        n_ensemble = ensemble.shape[1]\n",
        "        x_m = jnp.mean(ensemble, axis=1)\n",
        "        A = ensemble - x_m.reshape((-1, 1))\n",
        "        C_pred = (A @ A.T) / (n_ensemble - 1) + Q\n",
        "        C_pred = ledoit_wolf(C_pred, noise_const)\n",
        "        A = A * inflation\n",
        "        P =  (A @ A.T) / (n_ensemble - 1) + Q\n",
        "        K = P @ H.T @ jnp.linalg.inv(H @ P @ H.T + R)\n",
        "        x_m += K @ (y - H @ x_m)\n",
        "        M_sqrt = sqrt_m(jnp.eye(x_m.shape[0]) - K @ H)\n",
        "        updated_A = M_sqrt @ A\n",
        "        updated_ensemble = x_m.reshape((-1, 1)) + updated_A\n",
        "        updated_P = (updated_A @ updated_A.T) / (n_ensemble - 1)\n",
        "        updated_P = ledoit_wolf(updated_P, noise_const)\n",
        "\n",
        "        ensemble = ensemble.astype(jnp.float32)\n",
        "        C_pred = C_pred.astype(jnp.float32)\n",
        "        updated_ensemble = updated_ensemble.astype(jnp.float32)\n",
        "        updated_P = updated_P.astype(jnp.float32)\n",
        "        return ensemble, C_pred, updated_ensemble, updated_P\n",
        "\n",
        "    @jit\n",
        "    def sqrt_m(M):\n",
        "        eigenvalues, eigenvectors = jnp.linalg.eigh(M)\n",
        "        inv_sqrt_eigenvalues = jnp.sqrt(eigenvalues)\n",
        "        Lambda_inv_sqrt = jnp.diag(inv_sqrt_eigenvalues)\n",
        "        M_sqrt = eigenvectors @ Lambda_inv_sqrt @ eigenvectors.T\n",
        "        return M_sqrt.real\n",
        "\n",
        "    @partial(jit, static_argnums=(3))\n",
        "    def ensrf_steps(state_transition_function, n_ensemble, ensemble_init, num_steps, observations, observation_interval, H, Q, R, key):\n",
        "        model_vmap = jax.vmap(lambda v: state_transition_function(v), in_axes=1, out_axes=1)\n",
        "        key, *subkeys = random.split(key, num=num_steps + 1)\n",
        "        subkeys = jnp.array(subkeys)\n",
        "\n",
        "        def inner(carry, t):\n",
        "            ensemble, covar = carry\n",
        "            ensemble_predicted = model_vmap(ensemble)\n",
        "            _, C_forecast, ensemble_analysis, C_analysis = ensrf_step(ensemble_predicted, observations[t, :], H, Q, R, subkeys[t])\n",
        "            return (ensemble_analysis, C_analysis), (ensemble_predicted, C_forecast, ensemble_analysis, C_analysis)\n",
        "\n",
        "        n = len(Q[0])\n",
        "        covariance_init = jnp.zeros((n, n))\n",
        "        _, (ensemble_forecast, C_forecast, ensemble_analysis, C_analysis) = jax.lax.scan(inner, (ensemble_init, covariance_init), jnp.arange(num_steps))\n",
        "\n",
        "        return ensemble_forecast, C_forecast, ensemble_analysis, C_analysis\n",
        "\n",
        "    class IncrementCorrectionModel(nn.Module):\n",
        "        features: int\n",
        "\n",
        "        @nn.compact\n",
        "        def __call__(self, x):\n",
        "            x = nn.Dense(self.features)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = nn.Dense(self.features)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = nn.Dense(self.features)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = nn.Dense(x.shape[-1])(x)  # Output layer should match input dimension\n",
        "            return x\n",
        "\n",
        "    def create_model(key, input_shape, features):\n",
        "        model = IncrementCorrectionModel(features)\n",
        "        params = model.init(key, jnp.ones(input_shape))['params']\n",
        "        return model, params\n",
        "\n",
        "    def loss_fn(params, apply_fn, x, y):\n",
        "        predictions = apply_fn({'params': params}, x)\n",
        "        loss = jnp.mean((predictions - y) ** 2)\n",
        "        return loss\n",
        "\n",
        "    @jax.jit\n",
        "    def train_step(state, forecast_states, increments):\n",
        "        def loss_fn_wrapper(params):\n",
        "            return loss_fn(params, state.apply_fn, forecast_states, increments)\n",
        "\n",
        "        grads = jax.grad(loss_fn_wrapper)(state.params)\n",
        "        state = state.apply_gradients(grads=grads)\n",
        "        return state\n",
        "\n",
        "    def train_nn(state, forecast_states, analysis_states, num_epochs=10):\n",
        "        increments = analysis_states - forecast_states\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            state = train_step(state, forecast_states, increments)\n",
        "            current_loss = loss_fn(state.params, state.apply_fn, forecast_states, increments)\n",
        "            print(f'Epoch {epoch+1}, Loss: {current_loss}')\n",
        "\n",
        "        return state\n",
        "\n",
        "    Q = noise_const * jnp.eye(K)\n",
        "    H = jnp.eye(K)\n",
        "    R = jnp.eye(K) * noise_const\n",
        "    n_ensemble = 10\n",
        "    num_steps = time_steps\n",
        "    #the ensrf (ENKF) will run single scale Lorenz on the first K variables\n",
        "    observations = noisy_obs[:,:K]\n",
        "    initial_state = np.zeros((1, K))\n",
        "    ensemble_init = random.multivariate_normal(key, initial_state, Q, (n_ensemble,)).T\n",
        "    ensemble_forecast, C_forecast, ensemble_analysis, C_analysis = ensrf_steps(lorenz1, n_ensemble, ensemble_init, time_steps, observations, 1, H, Q, R, key)\n",
        "\n",
        "    time_steps = ensemble_forecast.shape[0]\n",
        "    time = jnp.arange(time_steps)\n",
        "\n",
        "    forecast_means = jnp.mean(ensemble_forecast, axis=2)\n",
        "    analysis_means = jnp.mean(ensemble_analysis, axis=2)\n",
        "\n",
        "    file = f\"ACM270_Model_Error/long_training_data_noise_{noise_const}_dt_{dt}.npz\"\n",
        "    data = np.load(file)\n",
        "    forecast_state = data[\"forecast\"]\n",
        "    analysis_state = data[\"analysis\"]\n",
        "\n",
        "    key = jax.random.PRNGKey(0)\n",
        "    input_shape = (K,)\n",
        "    features = K\n",
        "    model, params = create_model(key, input_shape, features)\n",
        "\n",
        "    learning_rate = 1e-3\n",
        "    optimizer = optax.adam(learning_rate)\n",
        "    state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=optimizer)\n",
        "\n",
        "    num_epochs = 15\n",
        "    _,_,n = forecast_state.shape\n",
        "    for i in range(n):\n",
        "      forecast_means = forecast_state[:,:,i]\n",
        "      analysis_means = analysis_state[:,:,i]\n",
        "      state = train_nn(state, forecast_means, analysis_means, num_epochs=num_epochs)\n",
        "\n",
        "    #@partial(jax.jit, static_argnums=(3))\n",
        "    def ensrf_steps_nn(state_transition_function, n_ensemble, ensemble_init, num_steps, observations, observation_interval, H, Q, R, key, nn_params, model):\n",
        "        def corrected_state_transition(v):\n",
        "            transition = state_transition_function(v)\n",
        "            correction = model.apply({'params': nn_params}, transition)\n",
        "            return transition + correction\n",
        "\n",
        "        model_vmap = jax.vmap(corrected_state_transition, in_axes=1, out_axes=1)\n",
        "        key, *subkeys = jax.random.split(key, num=num_steps + 1)\n",
        "        subkeys = jnp.array(subkeys)\n",
        "\n",
        "        def inner(carry, t):\n",
        "            ensemble, covar = carry\n",
        "            ensemble_predicted = model_vmap(ensemble)\n",
        "            _, C_forecast, ensemble_analysis, C_analysis = ensrf_step(ensemble_predicted, observations[t, :], H, Q, R, subkeys[t])\n",
        "            return (ensemble_analysis, C_analysis), (ensemble_predicted, C_forecast, ensemble_analysis, C_analysis)\n",
        "\n",
        "        n = len(Q[0])\n",
        "        covariance_init = jnp.zeros((n, n))\n",
        "        _, (ensemble_forecast, C_forecast, ensemble_analysis, C_analysis) = jax.lax.scan(inner, (ensemble_init, covariance_init), jnp.arange(num_steps))\n",
        "\n",
        "        return ensemble_forecast, C_forecast, ensemble_analysis, C_analysis\n",
        "\n",
        "    if dt == 0.01:\n",
        "      file = f\"testing_data_noise_{noise_const}_dt_{dt}.npz\"\n",
        "    else:\n",
        "      file = f\"ACM270_Model_Error/testing_data_noise_{noise_const}_dt_{dt}.npz\"\n",
        "    data = np.load(file)\n",
        "    noisy_trajectory = data[\"noisy_trajectory\"]\n",
        "    try:\n",
        "      trajectory=data['true_trajectory']\n",
        "    except:\n",
        "      trajectory=data['trajectory']\n",
        "\n",
        "    noisy_trajectory =  jnp.asarray(noisy_trajectory)\n",
        "    trajectory = jnp.asarray(trajectory)\n",
        "\n",
        "    NRMSE_fm = []\n",
        "    NRMSE_as = []\n",
        "    NRMSE_fm_NN = []\n",
        "    NRMSE_as_NN = []\n",
        "\n",
        "    _,_,n = noisy_trajectory.shape\n",
        "\n",
        "    for i in range(n):\n",
        "      observations = noisy_trajectory[:,:,i]\n",
        "\n",
        "      nn_params = state.params\n",
        "      ensemble_forecast_NN, C_forecast_NN, ensemble_analysis_NN, C_analysis_NN = ensrf_steps_nn(\n",
        "          lorenz1,\n",
        "          n_ensemble,\n",
        "          ensemble_init,\n",
        "          time_steps,\n",
        "          observations,\n",
        "          1,\n",
        "          H,\n",
        "          Q,\n",
        "          R,\n",
        "          key,\n",
        "          nn_params,\n",
        "          model\n",
        "      )\n",
        "\n",
        "      ensemble_forecast, C_forecast, ensemble_analysis, C_analysis = ensrf_steps(\n",
        "          lorenz1,\n",
        "          n_ensemble,\n",
        "          ensemble_init,\n",
        "          time_steps,\n",
        "          observations,\n",
        "          1,\n",
        "          H,\n",
        "          Q,\n",
        "          R,\n",
        "          key\n",
        "      )\n",
        "\n",
        "      time_steps = ensemble_forecast.shape[0]\n",
        "      time = jnp.arange(time_steps)\n",
        "\n",
        "      true_states = trajectory[:,:,i]\n",
        "      forecast_means = jnp.mean(ensemble_forecast, axis=2)\n",
        "      analysis_means = jnp.mean(ensemble_analysis, axis=2)\n",
        "\n",
        "      forecast_means_NN = jnp.mean(ensemble_forecast_NN, axis=2)\n",
        "      analysis_means_NN = jnp.mean(ensemble_analysis_NN, axis=2)\n",
        "\n",
        "      model_error = true_states - forecast_means\n",
        "      NRMSE_fm.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "      model_error = true_states - analysis_means\n",
        "      NRMSE_as.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "      model_error = true_states - forecast_means_NN\n",
        "      NRMSE_fm_NN.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "      model_error = true_states - analysis_means_NN\n",
        "      NRMSE_as_NN.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "\n",
        "    # full_NRMSE_fm.append(np.mean(NRMSE_fm))\n",
        "    # full_NRMSE_as.append(np.mean(NRMSE_as))\n",
        "    # full_NRMSE_fm_NN.append(np.mean(NRMSE_fm_NN))\n",
        "    # full_NRMSE_as_NN.append(np.mean(NRMSE_as_NN))\n",
        "    full_NRMSE_as[idx_n,idx_dt] = np.mean(NRMSE_as)\n",
        "    full_NRMSE_as_NN[idx_n,idx_dt] = np.mean(NRMSE_as_NN)\n",
        "    full_NRMSE_fm[idx_n,idx_dt] = np.mean(NRMSE_fm)\n",
        "    full_NRMSE_fm_NN[idx_n,idx_dt] = np.mean(NRMSE_fm_NN)\n",
        "\n",
        "fontsize = 20\n",
        "res = 500\n",
        "cols = ['k','b','orange','gray']\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(len(dts)):\n",
        "  plt.plot(noise_consts, full_NRMSE_as[:, i], label=f\"EnKF: dt={dts[i]}\", linestyle=\"-\", marker=\"o\",color=cols[i], linewidth=2.5,markersize=7)\n",
        "  plt.plot(noise_consts, full_NRMSE_as_NN[:, i], label=f\"NN: dt={dts[i]}\", linestyle=\"--\", marker=\"x\",color=cols[i], linewidth=2.5,markersize=7)\n",
        "\n",
        "plt.xlabel(\"Noise constant\",fontsize=fontsize)\n",
        "plt.ylabel(\"Total analysis NRMSE\",fontsize=fontsize)\n",
        "plt.title(\"Total analysis NRMSE vs noise levels\",fontsize=fontsize)\n",
        "# red_patch = mpatches.Patch(color='red', label='The red data')\n",
        "# plt.legend(handles=[red_patch])\n",
        "plt.legend(fontsize=fontsize/1.25)\n",
        "plt.grid(True)\n",
        "plt.xticks(fontsize=fontsize / 1.25)\n",
        "plt.yticks(fontsize=fontsize / 1.25)\n",
        "plt.savefig(\"analysis_MSE_vs_dt.png\", bbox_inches=\"tight\", dpi=res)\n",
        "\n",
        "# np.savez('MSE_results.npz', full_NRMSE_as=full_NRMSE_as,full_NRMSE_as_NN=full_NRMSE_as_NN, full_NRMSE_fm=full_NRMSE_fm, full_NRMSE_fm_NN=full_NRMSE_fm_NN)\n",
        "\n"
      ],
      "metadata": {
        "id": "-KzA-gYnooNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MSE vs. time"
      ],
      "metadata": {
        "id": "Hlttf5V0o_QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "!pip install filterpy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "from filterpy.kalman import EnsembleKalmanFilter as EnKF\n",
        "import scipy.integrate as integrate\n",
        "from scipy.interpolate import griddata\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "import optax\n",
        "from jax import jit, random, lax\n",
        "from jax.scipy.linalg import sqrtm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import integrate\n",
        "from jax.tree_util import Partial\n",
        "from functools import partial\n",
        "\n",
        "! rm -rf ACM270_Model_Error\n",
        "# if os.path.isdir('./ACM270_Model_Error/') == False:\n",
        "! git clone https://github.com/sreemanti-dey/ACM270_Model_Error.git\n",
        "sys.path.append('./ACM270_Model_Error/')\n",
        "\n",
        "! cd ACM270_Model_Error\n",
        "noise_consts = [0.1, 0.5]\n",
        "dts = [0.05, 0.1]\n",
        "\n",
        "for idx_n, noise_const in enumerate(noise_consts):\n",
        "  for idx_dt, dt in enumerate(dts):\n",
        "\n",
        "    \"\"\"# True Trajectory and Noisy Observations with 2-Scale Lorenz96\"\"\"\n",
        "    # parameters for two-scale L96\n",
        "    K = 36                      # number of large scale vars\n",
        "    J = 10                      # number of small scale vars per large var\n",
        "    h = 0.25                   # part of coupling\n",
        "    c = 10                     # part of coupling\n",
        "    b = 10                     # part of coupling\n",
        "    F = 10                     # forcing\n",
        "    # dt = 0.5                 # time step\n",
        "    # noise_const = 5\n",
        "    num_steps = 200\n",
        "    num_steps = int(num_steps * (0.05 / dt))\n",
        "    time_steps = num_steps\n",
        "\n",
        "    @jit\n",
        "    def L96_2(xy):\n",
        "        x = xy[0:K]\n",
        "        y = xy[K:].reshape(K, J)\n",
        "\n",
        "        dx = jnp.zeros(K)\n",
        "        dy = jnp.zeros((K, J))\n",
        "\n",
        "        for k in range(K):\n",
        "            dxdt = -1 * x[k - 1] * (x[k - 2] - x[(k + 1) % K]) - x[k] + F - (h * c / b) * jnp.sum(y[k])\n",
        "            dx = dx.at[k].set(dxdt)\n",
        "\n",
        "            for j in range(J):\n",
        "                dydt = -1 * c * b * y[k, (j + 1) % J] * (y[k, (j + 2) % J] - y[k, j - 1]) - c * y[k, j] + (h * c / b) * x[k]\n",
        "                dy = dy.at[k, j].set(dydt)\n",
        "\n",
        "        return jnp.concatenate([dx, dy.flatten()])\n",
        "\n",
        "    @jit\n",
        "    def rk4_step_lorenz96_2(x):\n",
        "        f = lambda y: L96_2(y)\n",
        "        k1 = dt * f(x)\n",
        "        k2 = dt * f(x + k1/2)\n",
        "        k3 = dt * f(x + k2/2)\n",
        "        k4 = dt * f(x + k3)\n",
        "        return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "    keys = iter(random.split(random.PRNGKey(0), 10))\n",
        "    key = random.PRNGKey(0)\n",
        "    # randomized starting point for large scale, 0 for small scale\n",
        "    x0 = np.linspace(0, 1, K)  # np.random.rand(K)\n",
        "    y0 = np.zeros((K, J))\n",
        "    xy0 = np.concatenate([x0, y0.flatten()])\n",
        "\n",
        "    rk4_step_lorenz96_2(xy0)\n",
        "\n",
        "    trajectory = jnp.zeros((time_steps, len(xy0)))\n",
        "    noisy_obs = jnp.zeros((time_steps, len(xy0)))\n",
        "    noise_covar = jnp.eye(len(xy0)) * noise_const\n",
        "\n",
        "    xy = xy0\n",
        "    for i in tqdm(range(time_steps)):\n",
        "        xy = rk4_step_lorenz96_2(xy)\n",
        "        trajectory = trajectory.at[i].set(xy)\n",
        "        # Add noise to the observations\n",
        "        noise = random.multivariate_normal(key, jnp.zeros(len(xy0)), noise_covar)\n",
        "        noisy_obs = noisy_obs.at[i].set(xy + noise)\n",
        "        key, _ = random.split(key)  # Update key for the next iteration\n",
        "\n",
        "    true_states = trajectory\n",
        "\n",
        "    @jit\n",
        "    def rk4_step_lorenz96_1(x):\n",
        "        f = lambda y: (jnp.roll(y, 1) - jnp.roll(y, -2)) * jnp.roll(y, -1) - y + F\n",
        "        k1 = dt * f(x)\n",
        "        k2 = dt * f(x + k1/2)\n",
        "        k3 = dt * f(x + k2/2)\n",
        "        k4 = dt * f(x + k3)\n",
        "        return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "    lorenz1 = Partial(rk4_step_lorenz96_1)\n",
        "    lorenz2 = Partial(rk4_step_lorenz96_2)\n",
        "\n",
        "    @jit\n",
        "    def ledoit_wolf(P, shrinkage):\n",
        "        return (1 - shrinkage) * P + shrinkage * jnp.trace(P) / P.shape[0] * jnp.eye(P.shape[0])\n",
        "\n",
        "    @jit\n",
        "    def ensrf_step(ensemble, y, H, Q, R, key, inflation = 1.2):\n",
        "        n_ensemble = ensemble.shape[1]\n",
        "        x_m = jnp.mean(ensemble, axis=1)\n",
        "        A = ensemble - x_m.reshape((-1, 1))\n",
        "        C_pred = (A @ A.T) / (n_ensemble - 1) + Q\n",
        "        C_pred = ledoit_wolf(C_pred, noise_const)\n",
        "        A = A * inflation\n",
        "        P =  (A @ A.T) / (n_ensemble - 1) + Q\n",
        "        K = P @ H.T @ jnp.linalg.inv(H @ P @ H.T + R)\n",
        "        x_m += K @ (y - H @ x_m)\n",
        "        M_sqrt = sqrt_m(jnp.eye(x_m.shape[0]) - K @ H)\n",
        "        updated_A = M_sqrt @ A\n",
        "        updated_ensemble = x_m.reshape((-1, 1)) + updated_A\n",
        "        updated_P = (updated_A @ updated_A.T) / (n_ensemble - 1)\n",
        "        updated_P = ledoit_wolf(updated_P, noise_const)\n",
        "\n",
        "        ensemble = ensemble.astype(jnp.float32)\n",
        "        C_pred = C_pred.astype(jnp.float32)\n",
        "        updated_ensemble = updated_ensemble.astype(jnp.float32)\n",
        "        updated_P = updated_P.astype(jnp.float32)\n",
        "        return ensemble, C_pred, updated_ensemble, updated_P\n",
        "\n",
        "    @jit\n",
        "    def sqrt_m(M):\n",
        "        eigenvalues, eigenvectors = jnp.linalg.eigh(M)\n",
        "        inv_sqrt_eigenvalues = jnp.sqrt(eigenvalues)\n",
        "        Lambda_inv_sqrt = jnp.diag(inv_sqrt_eigenvalues)\n",
        "        M_sqrt = eigenvectors @ Lambda_inv_sqrt @ eigenvectors.T\n",
        "        return M_sqrt.real\n",
        "\n",
        "    @partial(jit, static_argnums=(3))\n",
        "    def ensrf_steps(state_transition_function, n_ensemble, ensemble_init, num_steps, observations, observation_interval, H, Q, R, key):\n",
        "        model_vmap = jax.vmap(lambda v: state_transition_function(v), in_axes=1, out_axes=1)\n",
        "        key, *subkeys = random.split(key, num=num_steps + 1)\n",
        "        subkeys = jnp.array(subkeys)\n",
        "\n",
        "        def inner(carry, t):\n",
        "            ensemble, covar = carry\n",
        "            ensemble_predicted = model_vmap(ensemble)\n",
        "            _, C_forecast, ensemble_analysis, C_analysis = ensrf_step(ensemble_predicted, observations[t, :], H, Q, R, subkeys[t])\n",
        "            return (ensemble_analysis, C_analysis), (ensemble_predicted, C_forecast, ensemble_analysis, C_analysis)\n",
        "\n",
        "        n = len(Q[0])\n",
        "        covariance_init = jnp.zeros((n, n))\n",
        "        _, (ensemble_forecast, C_forecast, ensemble_analysis, C_analysis) = jax.lax.scan(inner, (ensemble_init, covariance_init), jnp.arange(num_steps))\n",
        "\n",
        "        return ensemble_forecast, C_forecast, ensemble_analysis, C_analysis\n",
        "\n",
        "    class IncrementCorrectionModel(nn.Module):\n",
        "        features: int\n",
        "\n",
        "        @nn.compact\n",
        "        def __call__(self, x):\n",
        "            x = nn.Dense(self.features)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = nn.Dense(self.features)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = nn.Dense(self.features)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = nn.Dense(x.shape[-1])(x)  # Output layer should match input dimension\n",
        "            return x\n",
        "\n",
        "    def create_model(key, input_shape, features):\n",
        "        model = IncrementCorrectionModel(features)\n",
        "        params = model.init(key, jnp.ones(input_shape))['params']\n",
        "        return model, params\n",
        "\n",
        "    def loss_fn(params, apply_fn, x, y):\n",
        "        predictions = apply_fn({'params': params}, x)\n",
        "        loss = jnp.mean((predictions - y) ** 2)\n",
        "        return loss\n",
        "\n",
        "    @jax.jit\n",
        "    def train_step(state, forecast_states, increments):\n",
        "        def loss_fn_wrapper(params):\n",
        "            return loss_fn(params, state.apply_fn, forecast_states, increments)\n",
        "\n",
        "        grads = jax.grad(loss_fn_wrapper)(state.params)\n",
        "        state = state.apply_gradients(grads=grads)\n",
        "        return state\n",
        "\n",
        "    def train_nn(state, forecast_states, analysis_states, num_epochs=10):\n",
        "        increments = analysis_states - forecast_states\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            state = train_step(state, forecast_states, increments)\n",
        "            current_loss = loss_fn(state.params, state.apply_fn, forecast_states, increments)\n",
        "            print(f'Epoch {epoch+1}, Loss: {current_loss}')\n",
        "\n",
        "        return state\n",
        "\n",
        "    Q = noise_const * jnp.eye(K)\n",
        "    H = jnp.eye(K)\n",
        "    R = jnp.eye(K) * noise_const\n",
        "    n_ensemble = 10\n",
        "    num_steps = time_steps\n",
        "    #the ensrf (ENKF) will run single scale Lorenz on the first K variables\n",
        "    observations = noisy_obs[:,:K]\n",
        "    initial_state = np.zeros((1, K))\n",
        "    ensemble_init = random.multivariate_normal(key, initial_state, Q, (n_ensemble,)).T\n",
        "    ensemble_forecast, C_forecast, ensemble_analysis, C_analysis = ensrf_steps(lorenz1, n_ensemble, ensemble_init, time_steps, observations, 1, H, Q, R, key)\n",
        "\n",
        "    time_steps = ensemble_forecast.shape[0]\n",
        "    time = jnp.arange(time_steps)\n",
        "\n",
        "    forecast_means = jnp.mean(ensemble_forecast, axis=2)\n",
        "    analysis_means = jnp.mean(ensemble_analysis, axis=2)\n",
        "\n",
        "    if dt == 0.01:\n",
        "      file = f\"long_training_data_noise_{noise_const}_dt_{dt}.npz\"\n",
        "    else:\n",
        "      file = f\"ACM270_Model_Error/long_training_data_noise_{noise_const}_dt_{dt}.npz\"\n",
        "    data = np.load(file)\n",
        "    forecast_state = data[\"forecast\"]\n",
        "    analysis_state = data[\"analysis\"]\n",
        "\n",
        "    key = jax.random.PRNGKey(0)\n",
        "    input_shape = (K,)\n",
        "    features = K\n",
        "    model, params = create_model(key, input_shape, features)\n",
        "\n",
        "    learning_rate = 1e-3\n",
        "    optimizer = optax.adam(learning_rate)\n",
        "    state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=optimizer)\n",
        "\n",
        "    num_epochs = 15\n",
        "    _,_,n = forecast_state.shape\n",
        "    for i in range(n):\n",
        "      forecast_means = forecast_state[:,:,i]\n",
        "      analysis_means = analysis_state[:,:,i]\n",
        "      state = train_nn(state, forecast_means, analysis_means, num_epochs=num_epochs)\n",
        "\n",
        "    #@partial(jax.jit, static_argnums=(3))\n",
        "    def ensrf_steps_nn(state_transition_function, n_ensemble, ensemble_init, num_steps, observations, observation_interval, H, Q, R, key, nn_params, model):\n",
        "        def corrected_state_transition(v):\n",
        "            transition = state_transition_function(v)\n",
        "            correction = model.apply({'params': nn_params}, transition)\n",
        "            return transition + correction\n",
        "\n",
        "        model_vmap = jax.vmap(corrected_state_transition, in_axes=1, out_axes=1)\n",
        "        key, *subkeys = jax.random.split(key, num=num_steps + 1)\n",
        "        subkeys = jnp.array(subkeys)\n",
        "\n",
        "        def inner(carry, t):\n",
        "            ensemble, covar = carry\n",
        "            ensemble_predicted = model_vmap(ensemble)\n",
        "            _, C_forecast, ensemble_analysis, C_analysis = ensrf_step(ensemble_predicted, observations[t, :], H, Q, R, subkeys[t])\n",
        "            return (ensemble_analysis, C_analysis), (ensemble_predicted, C_forecast, ensemble_analysis, C_analysis)\n",
        "\n",
        "        n = len(Q[0])\n",
        "        covariance_init = jnp.zeros((n, n))\n",
        "        _, (ensemble_forecast, C_forecast, ensemble_analysis, C_analysis) = jax.lax.scan(inner, (ensemble_init, covariance_init), jnp.arange(num_steps))\n",
        "\n",
        "        return ensemble_forecast, C_forecast, ensemble_analysis, C_analysis\n",
        "\n",
        "    fontsize = 20\n",
        "    res = 500\n",
        "    file = f\"ACM270_Model_Error/testing_data_noise_{noise_const}_dt_{dt}.npz\"\n",
        "    data = np.load(file)\n",
        "    noisy_trajectory = data[\"noisy_trajectory\"]\n",
        "    try:\n",
        "      trajectory=data['true_trajectory']\n",
        "    except:\n",
        "      trajectory=data['trajectory']\n",
        "\n",
        "    noisy_trajectory =  jnp.asarray(noisy_trajectory)\n",
        "    trajectory = jnp.asarray(trajectory)\n",
        "\n",
        "    m,_,n = noisy_trajectory.shape\n",
        "\n",
        "    NRMSE_fm = np.zeros((m,))\n",
        "    NRMSE_as = np.zeros((m,))\n",
        "    NRMSE_fm_NN = np.zeros((m,))\n",
        "    NRMSE_as_NN = np.zeros((m,))\n",
        "\n",
        "    for i in range(n):\n",
        "      observations = noisy_trajectory[:,:,i]\n",
        "\n",
        "      nn_params = state.params\n",
        "      ensemble_forecast_NN, C_forecast_NN, ensemble_analysis_NN, C_analysis_NN = ensrf_steps_nn(\n",
        "          lorenz1,\n",
        "          n_ensemble,\n",
        "          ensemble_init,\n",
        "          time_steps,\n",
        "          observations,\n",
        "          1,\n",
        "          H,\n",
        "          Q,\n",
        "          R,\n",
        "          key,\n",
        "          nn_params,\n",
        "          model\n",
        "      )\n",
        "\n",
        "      ensemble_forecast, C_forecast, ensemble_analysis, C_analysis = ensrf_steps(\n",
        "          lorenz1,\n",
        "          n_ensemble,\n",
        "          ensemble_init,\n",
        "          time_steps,\n",
        "          observations,\n",
        "          1,\n",
        "          H,\n",
        "          Q,\n",
        "          R,\n",
        "          key\n",
        "      )\n",
        "\n",
        "      true_states = trajectory[:,:,i]\n",
        "      time_steps = ensemble_forecast.shape[0]\n",
        "      time = jnp.arange(time_steps)\n",
        "\n",
        "      forecast_means = jnp.mean(ensemble_forecast, axis=2)\n",
        "      analysis_means = jnp.mean(ensemble_analysis, axis=2)\n",
        "\n",
        "      forecast_means_NN = jnp.mean(ensemble_forecast_NN, axis=2)\n",
        "      analysis_means_NN = jnp.mean(ensemble_analysis_NN, axis=2)\n",
        "\n",
        "      model_error = true_states - forecast_means\n",
        "      NRMSE_fm += (np.diag(model_error @ model_error.T) / np.diag(true_states @ true_states.T))\n",
        "      model_error = true_states - analysis_means\n",
        "      NRMSE_as += (np.diag(model_error @ model_error.T) / np.diag(true_states @ true_states.T))\n",
        "      model_error = true_states - forecast_means_NN\n",
        "      NRMSE_fm_NN += (np.diag(model_error @ model_error.T) / np.diag(true_states @ true_states.T))\n",
        "      model_error = true_states - analysis_means_NN\n",
        "      NRMSE_as_NN += (np.diag(model_error @ model_error.T) / np.diag(true_states @ true_states.T))\n",
        "\n",
        "    NRMSE_fm /= n\n",
        "    NRMSE_as /= n\n",
        "    NRMSE_fm_NN /= n\n",
        "    NRMSE_as_NN /= n\n",
        "\n",
        "    time = np.arange(0, time_steps)*dt\n",
        "    fontsize = 25\n",
        "\n",
        "    plt.figure(figsize=(14, 8))\n",
        "\n",
        "    i = 0  # Index of the state variable to plot\n",
        "    plt.plot(time, NRMSE_fm, label=f\"Forecast (uncorrected)\", linestyle=\"-\", marker=\"o\", color = 'k', linewidth=2.5,markersize=7)\n",
        "    plt.plot(time, NRMSE_as, label=f\"Analysis (uncorrected)\", linestyle=\"-\", marker=\"x\", color = 'k', linewidth=2.5,markersize=7)\n",
        "    plt.plot(time, NRMSE_fm_NN, label=f\"Forecast (corrected)\", linestyle=\"--\", marker=\"o\", color = 'b', linewidth=2.5,markersize=7)\n",
        "    plt.plot(time, NRMSE_as_NN, label=f\"Analysis (corrected)\", linestyle=\"--\", marker=\"x\", color = 'b', linewidth=2.5,markersize=7)\n",
        "\n",
        "    plt.xlabel(\"Time\",fontsize=fontsize)\n",
        "    plt.ylabel(\"Average NRMSE\",fontsize=fontsize)\n",
        "    plt.title(f\"Average NRMSE vs time\",fontsize=fontsize)\n",
        "    plt.legend(fontsize=fontsize/1.5)\n",
        "    plt.grid(True)\n",
        "    plt.xticks(fontsize=fontsize / 1.25)\n",
        "    plt.yticks(fontsize=fontsize / 1.25)\n",
        "    # plt.show()\n",
        "    plt.savefig(f'long_MSE_vs_time_noise_{noise_const}_dt_{dt}.png', bbox_inches=\"tight\", dpi=res)"
      ],
      "metadata": {
        "id": "pGBKtkJupHTq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MSE vs. training data"
      ],
      "metadata": {
        "id": "Y6SdVlfzpI5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "!pip install filterpy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "from filterpy.kalman import EnsembleKalmanFilter as EnKF\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.integrate as integrate\n",
        "from scipy.interpolate import griddata\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "import optax\n",
        "from jax import jit, random, lax\n",
        "from jax.scipy.linalg import sqrtm\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import integrate\n",
        "from jax.tree_util import Partial\n",
        "from functools import partial\n",
        "\n",
        "! rm -rf ACM270_Model_Error\n",
        "# if os.path.isdir('./ACM270_Model_Error/') == False:\n",
        "! git clone https://github.com/sreemanti-dey/ACM270_Model_Error.git\n",
        "sys.path.append('./ACM270_Model_Error/')\n",
        "\n",
        "! cd ACM270_Model_Error\n",
        "\n",
        "\"\"\"# True Trajectory and Noisy Observations with 2-Scale Lorenz96\"\"\"\n",
        "\n",
        "full_NRMSE_fm = []\n",
        "full_NRMSE_as = []\n",
        "full_NRMSE_fm_NN = []\n",
        "full_NRMSE_as_NN = []\n",
        "\n",
        "training_data = np.linspace(1,50,15, dtype=int)\n",
        "\n",
        "for idx_n, train_data in enumerate(training_data):\n",
        "    # parameters for two-scale L96\n",
        "    K = 36                      # number of large scale vars\n",
        "    J = 10                      # number of small scale vars per large var\n",
        "    h = 0.25                   # part of coupling\n",
        "    c = 10                     # part of coupling\n",
        "    b = 10                     # part of coupling\n",
        "    F = 10                     # forcing\n",
        "    dt = 0.1                  # time step\n",
        "    noise_const = 0.1\n",
        "    num_steps = 200\n",
        "    num_steps = int(num_steps * (0.05 / dt))\n",
        "    time_steps = num_steps\n",
        "\n",
        "    @jit\n",
        "    def L96_2(xy):\n",
        "        x = xy[0:K]\n",
        "        y = xy[K:].reshape(K, J)\n",
        "\n",
        "        dx = jnp.zeros(K)\n",
        "        dy = jnp.zeros((K, J))\n",
        "\n",
        "        for k in range(K):\n",
        "            dxdt = -1 * x[k - 1] * (x[k - 2] - x[(k + 1) % K]) - x[k] + F - (h * c / b) * jnp.sum(y[k])\n",
        "            dx = dx.at[k].set(dxdt)\n",
        "\n",
        "            for j in range(J):\n",
        "                dydt = -1 * c * b * y[k, (j + 1) % J] * (y[k, (j + 2) % J] - y[k, j - 1]) - c * y[k, j] + (h * c / b) * x[k]\n",
        "                dy = dy.at[k, j].set(dydt)\n",
        "\n",
        "        return jnp.concatenate([dx, dy.flatten()])\n",
        "\n",
        "    @jit\n",
        "    def rk4_step_lorenz96_2(x):\n",
        "        f = lambda y: L96_2(y)\n",
        "        k1 = dt * f(x)\n",
        "        k2 = dt * f(x + k1/2)\n",
        "        k3 = dt * f(x + k2/2)\n",
        "        k4 = dt * f(x + k3)\n",
        "        return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "    keys = iter(random.split(random.PRNGKey(0), 10))\n",
        "    key = random.PRNGKey(0)\n",
        "    # randomized starting point for large scale, 0 for small scale\n",
        "    x0 = np.linspace(0, 1, K)  # np.random.rand(K)\n",
        "    y0 = np.zeros((K, J))\n",
        "    xy0 = np.concatenate([x0, y0.flatten()])\n",
        "\n",
        "    rk4_step_lorenz96_2(xy0)\n",
        "\n",
        "    trajectory = jnp.zeros((time_steps, len(xy0)))\n",
        "    noisy_obs = jnp.zeros((time_steps, len(xy0)))\n",
        "    noise_covar = jnp.eye(len(xy0)) * noise_const\n",
        "\n",
        "    xy = xy0\n",
        "    for i in tqdm(range(time_steps)):\n",
        "        xy = rk4_step_lorenz96_2(xy)\n",
        "        trajectory = trajectory.at[i].set(xy)\n",
        "        # Add noise to the observations\n",
        "        noise = random.multivariate_normal(key, jnp.zeros(len(xy0)), noise_covar)\n",
        "        noisy_obs = noisy_obs.at[i].set(xy + noise)\n",
        "        key, _ = random.split(key)  # Update key for the next iteration\n",
        "\n",
        "    \"\"\"## True Trajectory\n",
        "\n",
        "    ## Noisy Observations\n",
        "    \"\"\"\n",
        "\n",
        "    true_states = trajectory\n",
        "\n",
        "    \"\"\"# EnKF for 1-Scale Assimilation\"\"\"\n",
        "\n",
        "    @jit\n",
        "    def rk4_step_lorenz96_1(x):\n",
        "        f = lambda y: (jnp.roll(y, 1) - jnp.roll(y, -2)) * jnp.roll(y, -1) - y + F\n",
        "        k1 = dt * f(x)\n",
        "        k2 = dt * f(x + k1/2)\n",
        "        k3 = dt * f(x + k2/2)\n",
        "        k4 = dt * f(x + k3)\n",
        "        return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "    lorenz1 = Partial(rk4_step_lorenz96_1)\n",
        "    lorenz2 = Partial(rk4_step_lorenz96_2)\n",
        "\n",
        "    @jit\n",
        "    def ledoit_wolf(P, shrinkage):\n",
        "        return (1 - shrinkage) * P + shrinkage * jnp.trace(P) / P.shape[0] * jnp.eye(P.shape[0])\n",
        "\n",
        "    @jit\n",
        "    def ensrf_step(ensemble, y, H, Q, R, key, inflation = 1.2):\n",
        "        n_ensemble = ensemble.shape[1]\n",
        "        x_m = jnp.mean(ensemble, axis=1)\n",
        "        A = ensemble - x_m.reshape((-1, 1))\n",
        "        C_pred = (A @ A.T) / (n_ensemble - 1) + Q\n",
        "        C_pred = ledoit_wolf(C_pred, noise_const)\n",
        "        A = A * inflation\n",
        "        P =  (A @ A.T) / (n_ensemble - 1) + Q\n",
        "        K = P @ H.T @ jnp.linalg.inv(H @ P @ H.T + R)\n",
        "        x_m += K @ (y - H @ x_m)\n",
        "        M_sqrt = sqrt_m(jnp.eye(x_m.shape[0]) - K @ H)\n",
        "        updated_A = M_sqrt @ A\n",
        "        updated_ensemble = x_m.reshape((-1, 1)) + updated_A\n",
        "        updated_P = (updated_A @ updated_A.T) / (n_ensemble - 1)\n",
        "        updated_P = ledoit_wolf(updated_P, noise_const)\n",
        "\n",
        "        ensemble = ensemble.astype(jnp.float32)\n",
        "        C_pred = C_pred.astype(jnp.float32)\n",
        "        updated_ensemble = updated_ensemble.astype(jnp.float32)\n",
        "        updated_P = updated_P.astype(jnp.float32)\n",
        "        return ensemble, C_pred, updated_ensemble, updated_P\n",
        "\n",
        "    @jit\n",
        "    def sqrt_m(M):\n",
        "        eigenvalues, eigenvectors = jnp.linalg.eigh(M)\n",
        "        inv_sqrt_eigenvalues = jnp.sqrt(eigenvalues)\n",
        "        Lambda_inv_sqrt = jnp.diag(inv_sqrt_eigenvalues)\n",
        "        M_sqrt = eigenvectors @ Lambda_inv_sqrt @ eigenvectors.T\n",
        "        return M_sqrt.real\n",
        "\n",
        "    @partial(jit, static_argnums=(3))\n",
        "    def ensrf_steps(state_transition_function, n_ensemble, ensemble_init, num_steps, observations, observation_interval, H, Q, R, key):\n",
        "        model_vmap = jax.vmap(lambda v: state_transition_function(v), in_axes=1, out_axes=1)\n",
        "        key, *subkeys = random.split(key, num=num_steps + 1)\n",
        "        subkeys = jnp.array(subkeys)\n",
        "\n",
        "        def inner(carry, t):\n",
        "            ensemble, covar = carry\n",
        "            ensemble_predicted = model_vmap(ensemble)\n",
        "            _, C_forecast, ensemble_analysis, C_analysis = ensrf_step(ensemble_predicted, observations[t, :], H, Q, R, subkeys[t])\n",
        "            return (ensemble_analysis, C_analysis), (ensemble_predicted, C_forecast, ensemble_analysis, C_analysis)\n",
        "\n",
        "        n = len(Q[0])\n",
        "        covariance_init = jnp.zeros((n, n))\n",
        "        _, (ensemble_forecast, C_forecast, ensemble_analysis, C_analysis) = jax.lax.scan(inner, (ensemble_init, covariance_init), jnp.arange(num_steps))\n",
        "\n",
        "        return ensemble_forecast, C_forecast, ensemble_analysis, C_analysis\n",
        "\n",
        "    class IncrementCorrectionModel(nn.Module):\n",
        "        features: int\n",
        "\n",
        "        @nn.compact\n",
        "        def __call__(self, x):\n",
        "            x = nn.Dense(self.features)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = nn.Dense(self.features)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = nn.Dense(self.features)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = nn.Dense(x.shape[-1])(x)  # Output layer should match input dimension\n",
        "            return x\n",
        "\n",
        "    def create_model(key, input_shape, features):\n",
        "        model = IncrementCorrectionModel(features)\n",
        "        params = model.init(key, jnp.ones(input_shape))['params']\n",
        "        return model, params\n",
        "\n",
        "    def loss_fn(params, apply_fn, x, y):\n",
        "        predictions = apply_fn({'params': params}, x)\n",
        "        loss = jnp.mean((predictions - y) ** 2)\n",
        "        return loss\n",
        "\n",
        "    @jax.jit\n",
        "    def train_step(state, forecast_states, increments):\n",
        "        def loss_fn_wrapper(params):\n",
        "            return loss_fn(params, state.apply_fn, forecast_states, increments)\n",
        "\n",
        "        grads = jax.grad(loss_fn_wrapper)(state.params)\n",
        "        state = state.apply_gradients(grads=grads)\n",
        "        return state\n",
        "\n",
        "    def train_nn(state, forecast_states, analysis_states, num_epochs=10):\n",
        "        increments = analysis_states - forecast_states\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            state = train_step(state, forecast_states, increments)\n",
        "            current_loss = loss_fn(state.params, state.apply_fn, forecast_states, increments)\n",
        "            print(f'Epoch {epoch+1}, Loss: {current_loss}')\n",
        "\n",
        "        return state\n",
        "\n",
        "    Q = noise_const * jnp.eye(K)\n",
        "    H = jnp.eye(K)\n",
        "    R = jnp.eye(K) * noise_const\n",
        "    n_ensemble = 10\n",
        "    num_steps = time_steps\n",
        "    #the ensrf (ENKF) will run single scale Lorenz on the first K variables\n",
        "    observations = noisy_obs[:,:K]\n",
        "    initial_state = np.zeros((1, K))\n",
        "    ensemble_init = random.multivariate_normal(key, initial_state, Q, (n_ensemble,)).T\n",
        "    ensemble_forecast, C_forecast, ensemble_analysis, C_analysis = ensrf_steps(lorenz1, n_ensemble, ensemble_init, time_steps, observations, 1, H, Q, R, key)\n",
        "\n",
        "    time_steps = ensemble_forecast.shape[0]\n",
        "    time = jnp.arange(time_steps)\n",
        "\n",
        "    forecast_means = jnp.mean(ensemble_forecast, axis=2)\n",
        "    analysis_means = jnp.mean(ensemble_analysis, axis=2)\n",
        "\n",
        "    file = f\"ACM270_Model_Error/long_training_data_noise_{noise_const}_dt_{dt}.npz\"\n",
        "    data = np.load(file)\n",
        "    forecast_state = data[\"forecast\"]\n",
        "    analysis_state = data[\"analysis\"]\n",
        "\n",
        "    key = jax.random.PRNGKey(0)\n",
        "    input_shape = (K,)\n",
        "    features = K\n",
        "    model, params = create_model(key, input_shape, features)\n",
        "\n",
        "    learning_rate = 1e-3\n",
        "    optimizer = optax.adam(learning_rate)\n",
        "    state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=optimizer)\n",
        "\n",
        "    num_epochs = 15\n",
        "    _,_,n = forecast_state.shape\n",
        "    for i in range(train_data):\n",
        "      forecast_means = forecast_state[:,:,i]\n",
        "      analysis_means = analysis_state[:,:,i]\n",
        "      state = train_nn(state, forecast_means, analysis_means, num_epochs=num_epochs)\n",
        "\n",
        "    #@partial(jax.jit, static_argnums=(3))\n",
        "    def ensrf_steps_nn(state_transition_function, n_ensemble, ensemble_init, num_steps, observations, observation_interval, H, Q, R, key, nn_params, model):\n",
        "        def corrected_state_transition(v):\n",
        "            transition = state_transition_function(v)\n",
        "            correction = model.apply({'params': nn_params}, transition)\n",
        "            return transition + correction\n",
        "\n",
        "        model_vmap = jax.vmap(corrected_state_transition, in_axes=1, out_axes=1)\n",
        "        key, *subkeys = jax.random.split(key, num=num_steps + 1)\n",
        "        subkeys = jnp.array(subkeys)\n",
        "\n",
        "        def inner(carry, t):\n",
        "            ensemble, covar = carry\n",
        "            ensemble_predicted = model_vmap(ensemble)\n",
        "            _, C_forecast, ensemble_analysis, C_analysis = ensrf_step(ensemble_predicted, observations[t, :], H, Q, R, subkeys[t])\n",
        "            return (ensemble_analysis, C_analysis), (ensemble_predicted, C_forecast, ensemble_analysis, C_analysis)\n",
        "\n",
        "        n = len(Q[0])\n",
        "        covariance_init = jnp.zeros((n, n))\n",
        "        _, (ensemble_forecast, C_forecast, ensemble_analysis, C_analysis) = jax.lax.scan(inner, (ensemble_init, covariance_init), jnp.arange(num_steps))\n",
        "\n",
        "        return ensemble_forecast, C_forecast, ensemble_analysis, C_analysis\n",
        "\n",
        "    file = f\"ACM270_Model_Error/testing_data_noise_{noise_const}_dt_{dt}.npz\"\n",
        "    data = np.load(file)\n",
        "    noisy_trajectory = data[\"noisy_trajectory\"]\n",
        "    try:\n",
        "      trajectory=data['true_trajectory']\n",
        "    except:\n",
        "      trajectory=data['trajectory']\n",
        "\n",
        "    noisy_trajectory =  jnp.asarray(noisy_trajectory)\n",
        "    trajectory = jnp.asarray(trajectory)\n",
        "\n",
        "    NRMSE_fm = []\n",
        "    NRMSE_as = []\n",
        "    NRMSE_fm_NN = []\n",
        "    NRMSE_as_NN = []\n",
        "\n",
        "    _,_,n = noisy_trajectory.shape\n",
        "\n",
        "    for i in range(n):\n",
        "      observations = noisy_trajectory[:,:,i]\n",
        "\n",
        "      nn_params = state.params\n",
        "      ensemble_forecast_NN, C_forecast_NN, ensemble_analysis_NN, C_analysis_NN = ensrf_steps_nn(\n",
        "          lorenz1,\n",
        "          n_ensemble,\n",
        "          ensemble_init,\n",
        "          time_steps,\n",
        "          observations,\n",
        "          1,\n",
        "          H,\n",
        "          Q,\n",
        "          R,\n",
        "          key,\n",
        "          nn_params,\n",
        "          model\n",
        "      )\n",
        "\n",
        "      ensemble_forecast, C_forecast, ensemble_analysis, C_analysis = ensrf_steps(\n",
        "          lorenz1,\n",
        "          n_ensemble,\n",
        "          ensemble_init,\n",
        "          time_steps,\n",
        "          observations,\n",
        "          1,\n",
        "          H,\n",
        "          Q,\n",
        "          R,\n",
        "          key\n",
        "      )\n",
        "\n",
        "      time_steps = ensemble_forecast.shape[0]\n",
        "      time = jnp.arange(time_steps)\n",
        "\n",
        "      true_states = trajectory[:,:,i]\n",
        "      forecast_means = jnp.mean(ensemble_forecast, axis=2)\n",
        "      analysis_means = jnp.mean(ensemble_analysis, axis=2)\n",
        "\n",
        "      forecast_means_NN = jnp.mean(ensemble_forecast_NN, axis=2)\n",
        "      analysis_means_NN = jnp.mean(ensemble_analysis_NN, axis=2)\n",
        "\n",
        "      model_error = true_states - forecast_means\n",
        "      NRMSE_fm.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "      model_error = true_states - analysis_means\n",
        "      NRMSE_as.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "      model_error = true_states - forecast_means_NN\n",
        "      NRMSE_fm_NN.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "      model_error = true_states - analysis_means_NN\n",
        "      NRMSE_as_NN.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "\n",
        "    full_NRMSE_fm.append(np.mean(NRMSE_fm))\n",
        "    full_NRMSE_as.append(np.mean(NRMSE_as))\n",
        "    full_NRMSE_fm_NN.append(np.mean(NRMSE_fm_NN))\n",
        "    full_NRMSE_as_NN.append(np.mean(NRMSE_as_NN))\n",
        "\n",
        "fontsize = 20\n",
        "res = 500\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(training_data, full_NRMSE_as, label=\"Analysis (uncorrected)\", linestyle=\"-\",color='k', linewidth=2.5,markersize=7)\n",
        "plt.plot(training_data, full_NRMSE_as_NN, label=\"Analysis (corrected)\", linestyle=\"-\", marker=\"o\",color='b', linewidth=2.5,markersize=7)\n",
        "plt.plot(training_data, full_NRMSE_fm, label=\"Forecast (uncorrected)\", linestyle=\"--\",color='k', linewidth=2.5,markersize=7)\n",
        "plt.plot(training_data, full_NRMSE_fm_NN, label=\"Forecast (corrected)\", linestyle=\"--\", marker=\"x\",color='b', linewidth=2.5,markersize=7)\n",
        "\n",
        "plt.xlabel(\"Trajectories used in training\",fontsize=fontsize)\n",
        "plt.ylabel(\"Total NRMSE\",fontsize=fontsize)\n",
        "plt.title(\"Total NRMSE vs training trajectories\",fontsize=fontsize)\n",
        "plt.legend(fontsize=fontsize/1.25)\n",
        "plt.grid(True)\n",
        "plt.xticks(fontsize=fontsize / 1.25)\n",
        "plt.yticks(fontsize=fontsize / 1.25)\n",
        "plt.savefig(f\"analysis_MSE_vs_traindata_noise_{noise_const}_dt_{dt}.png\", bbox_inches=\"tight\", dpi=res)\n",
        "\n"
      ],
      "metadata": {
        "id": "O85PdadmpMgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MSE vs. Epoch"
      ],
      "metadata": {
        "id": "s6x6aVywphgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "!pip install filterpy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "from filterpy.kalman import EnsembleKalmanFilter as EnKF\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.integrate as integrate\n",
        "from scipy.interpolate import griddata\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "import optax\n",
        "from jax import jit, random, lax\n",
        "from jax.scipy.linalg import sqrtm\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import integrate\n",
        "from jax.tree_util import Partial\n",
        "from functools import partial\n",
        "\n",
        "! rm -rf ACM270_Model_Error\n",
        "# if os.path.isdir('./ACM270_Model_Error/') == False:\n",
        "! git clone https://github.com/sreemanti-dey/ACM270_Model_Error.git\n",
        "sys.path.append('./ACM270_Model_Error/')\n",
        "\n",
        "! cd ACM270_Model_Error\n",
        "\n",
        "\"\"\"# True Trajectory and Noisy Observations with 2-Scale Lorenz96\"\"\"\n",
        "\n",
        "full_NRMSE_fm = []\n",
        "full_NRMSE_as = []\n",
        "full_NRMSE_fm_NN = []\n",
        "full_NRMSE_as_NN = []\n",
        "\n",
        "epochs = np.linspace(1,50,15, dtype=int)\n",
        "\n",
        "for idx_n, train_epoch in enumerate(epochs):\n",
        "    # parameters for two-scale L96\n",
        "    K = 36                      # number of large scale vars\n",
        "    J = 10                      # number of small scale vars per large var\n",
        "    h = 0.25                   # part of coupling\n",
        "    c = 10                     # part of coupling\n",
        "    b = 10                     # part of coupling\n",
        "    F = 10                     # forcing\n",
        "    dt = 0.05                  # time step\n",
        "    noise_const = 0.1\n",
        "    num_steps = 200\n",
        "    num_steps = int(num_steps * (0.05 / dt))\n",
        "    time_steps = num_steps\n",
        "\n",
        "    @jit\n",
        "    def L96_2(xy):\n",
        "        x = xy[0:K]\n",
        "        y = xy[K:].reshape(K, J)\n",
        "\n",
        "        dx = jnp.zeros(K)\n",
        "        dy = jnp.zeros((K, J))\n",
        "\n",
        "        for k in range(K):\n",
        "            dxdt = -1 * x[k - 1] * (x[k - 2] - x[(k + 1) % K]) - x[k] + F - (h * c / b) * jnp.sum(y[k])\n",
        "            dx = dx.at[k].set(dxdt)\n",
        "\n",
        "            for j in range(J):\n",
        "                dydt = -1 * c * b * y[k, (j + 1) % J] * (y[k, (j + 2) % J] - y[k, j - 1]) - c * y[k, j] + (h * c / b) * x[k]\n",
        "                dy = dy.at[k, j].set(dydt)\n",
        "\n",
        "        return jnp.concatenate([dx, dy.flatten()])\n",
        "\n",
        "    @jit\n",
        "    def rk4_step_lorenz96_2(x):\n",
        "        f = lambda y: L96_2(y)\n",
        "        k1 = dt * f(x)\n",
        "        k2 = dt * f(x + k1/2)\n",
        "        k3 = dt * f(x + k2/2)\n",
        "        k4 = dt * f(x + k3)\n",
        "        return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "    keys = iter(random.split(random.PRNGKey(0), 10))\n",
        "    key = random.PRNGKey(0)\n",
        "    # randomized starting point for large scale, 0 for small scale\n",
        "    x0 = np.linspace(0, 1, K)  # np.random.rand(K)\n",
        "    y0 = np.zeros((K, J))\n",
        "    xy0 = np.concatenate([x0, y0.flatten()])\n",
        "\n",
        "    rk4_step_lorenz96_2(xy0)\n",
        "\n",
        "    trajectory = jnp.zeros((time_steps, len(xy0)))\n",
        "    noisy_obs = jnp.zeros((time_steps, len(xy0)))\n",
        "    noise_covar = jnp.eye(len(xy0)) * noise_const\n",
        "\n",
        "    xy = xy0\n",
        "    for i in tqdm(range(time_steps)):\n",
        "        xy = rk4_step_lorenz96_2(xy)\n",
        "        trajectory = trajectory.at[i].set(xy)\n",
        "        # Add noise to the observations\n",
        "        noise = random.multivariate_normal(key, jnp.zeros(len(xy0)), noise_covar)\n",
        "        noisy_obs = noisy_obs.at[i].set(xy + noise)\n",
        "        key, _ = random.split(key)  # Update key for the next iteration\n",
        "\n",
        "    \"\"\"## True Trajectory\n",
        "\n",
        "    ## Noisy Observations\n",
        "    \"\"\"\n",
        "\n",
        "    true_states = trajectory\n",
        "\n",
        "    \"\"\"# EnKF for 1-Scale Assimilation\"\"\"\n",
        "\n",
        "    @jit\n",
        "    def rk4_step_lorenz96_1(x):\n",
        "        f = lambda y: (jnp.roll(y, 1) - jnp.roll(y, -2)) * jnp.roll(y, -1) - y + F\n",
        "        k1 = dt * f(x)\n",
        "        k2 = dt * f(x + k1/2)\n",
        "        k3 = dt * f(x + k2/2)\n",
        "        k4 = dt * f(x + k3)\n",
        "        return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "    lorenz1 = Partial(rk4_step_lorenz96_1)\n",
        "    lorenz2 = Partial(rk4_step_lorenz96_2)\n",
        "\n",
        "    @jit\n",
        "    def ledoit_wolf(P, shrinkage):\n",
        "        return (1 - shrinkage) * P + shrinkage * jnp.trace(P) / P.shape[0] * jnp.eye(P.shape[0])\n",
        "\n",
        "    @jit\n",
        "    def ensrf_step(ensemble, y, H, Q, R, key, inflation = 1.2):\n",
        "        n_ensemble = ensemble.shape[1]\n",
        "        x_m = jnp.mean(ensemble, axis=1)\n",
        "        A = ensemble - x_m.reshape((-1, 1))\n",
        "        C_pred = (A @ A.T) / (n_ensemble - 1) + Q\n",
        "        C_pred = ledoit_wolf(C_pred, noise_const)\n",
        "        A = A * inflation\n",
        "        P =  (A @ A.T) / (n_ensemble - 1) + Q\n",
        "        K = P @ H.T @ jnp.linalg.inv(H @ P @ H.T + R)\n",
        "        x_m += K @ (y - H @ x_m)\n",
        "        M_sqrt = sqrt_m(jnp.eye(x_m.shape[0]) - K @ H)\n",
        "        updated_A = M_sqrt @ A\n",
        "        updated_ensemble = x_m.reshape((-1, 1)) + updated_A\n",
        "        updated_P = (updated_A @ updated_A.T) / (n_ensemble - 1)\n",
        "        updated_P = ledoit_wolf(updated_P, noise_const)\n",
        "\n",
        "        ensemble = ensemble.astype(jnp.float32)\n",
        "        C_pred = C_pred.astype(jnp.float32)\n",
        "        updated_ensemble = updated_ensemble.astype(jnp.float32)\n",
        "        updated_P = updated_P.astype(jnp.float32)\n",
        "        return ensemble, C_pred, updated_ensemble, updated_P\n",
        "\n",
        "    @jit\n",
        "    def sqrt_m(M):\n",
        "        eigenvalues, eigenvectors = jnp.linalg.eigh(M)\n",
        "        inv_sqrt_eigenvalues = jnp.sqrt(eigenvalues)\n",
        "        Lambda_inv_sqrt = jnp.diag(inv_sqrt_eigenvalues)\n",
        "        M_sqrt = eigenvectors @ Lambda_inv_sqrt @ eigenvectors.T\n",
        "        return M_sqrt.real\n",
        "\n",
        "    @partial(jit, static_argnums=(3))\n",
        "    def ensrf_steps(state_transition_function, n_ensemble, ensemble_init, num_steps, observations, observation_interval, H, Q, R, key):\n",
        "        model_vmap = jax.vmap(lambda v: state_transition_function(v), in_axes=1, out_axes=1)\n",
        "        key, *subkeys = random.split(key, num=num_steps + 1)\n",
        "        subkeys = jnp.array(subkeys)\n",
        "\n",
        "        def inner(carry, t):\n",
        "            ensemble, covar = carry\n",
        "            ensemble_predicted = model_vmap(ensemble)\n",
        "            _, C_forecast, ensemble_analysis, C_analysis = ensrf_step(ensemble_predicted, observations[t, :], H, Q, R, subkeys[t])\n",
        "            return (ensemble_analysis, C_analysis), (ensemble_predicted, C_forecast, ensemble_analysis, C_analysis)\n",
        "\n",
        "        n = len(Q[0])\n",
        "        covariance_init = jnp.zeros((n, n))\n",
        "        _, (ensemble_forecast, C_forecast, ensemble_analysis, C_analysis) = jax.lax.scan(inner, (ensemble_init, covariance_init), jnp.arange(num_steps))\n",
        "\n",
        "        return ensemble_forecast, C_forecast, ensemble_analysis, C_analysis\n",
        "\n",
        "    class IncrementCorrectionModel(nn.Module):\n",
        "        features: int\n",
        "\n",
        "        @nn.compact\n",
        "        def __call__(self, x):\n",
        "            x = nn.Dense(self.features)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = nn.Dense(self.features)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = nn.Dense(self.features)(x)\n",
        "            x = nn.relu(x)\n",
        "            x = nn.Dense(x.shape[-1])(x)  # Output layer should match input dimension\n",
        "            return x\n",
        "\n",
        "    def create_model(key, input_shape, features):\n",
        "        model = IncrementCorrectionModel(features)\n",
        "        params = model.init(key, jnp.ones(input_shape))['params']\n",
        "        return model, params\n",
        "\n",
        "    def loss_fn(params, apply_fn, x, y):\n",
        "        predictions = apply_fn({'params': params}, x)\n",
        "        loss = jnp.mean((predictions - y) ** 2)\n",
        "        return loss\n",
        "\n",
        "    @jax.jit\n",
        "    def train_step(state, forecast_states, increments):\n",
        "        def loss_fn_wrapper(params):\n",
        "            return loss_fn(params, state.apply_fn, forecast_states, increments)\n",
        "\n",
        "        grads = jax.grad(loss_fn_wrapper)(state.params)\n",
        "        state = state.apply_gradients(grads=grads)\n",
        "        return state\n",
        "\n",
        "    def train_nn(state, forecast_states, analysis_states, num_epochs=10):\n",
        "        increments = analysis_states - forecast_states\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            state = train_step(state, forecast_states, increments)\n",
        "            current_loss = loss_fn(state.params, state.apply_fn, forecast_states, increments)\n",
        "            print(f'Epoch {epoch+1}, Loss: {current_loss}')\n",
        "\n",
        "        return state\n",
        "\n",
        "    Q = noise_const * jnp.eye(K)\n",
        "    H = jnp.eye(K)\n",
        "    R = jnp.eye(K) * noise_const\n",
        "    n_ensemble = 10\n",
        "    num_steps = time_steps\n",
        "    #the ensrf (ENKF) will run single scale Lorenz on the first K variables\n",
        "    observations = noisy_obs[:,:K]\n",
        "    initial_state = np.zeros((1, K))\n",
        "    ensemble_init = random.multivariate_normal(key, initial_state, Q, (n_ensemble,)).T\n",
        "    ensemble_forecast, C_forecast, ensemble_analysis, C_analysis = ensrf_steps(lorenz1, n_ensemble, ensemble_init, time_steps, observations, 1, H, Q, R, key)\n",
        "\n",
        "    time_steps = ensemble_forecast.shape[0]\n",
        "    time = jnp.arange(time_steps)\n",
        "\n",
        "    forecast_means = jnp.mean(ensemble_forecast, axis=2)\n",
        "    analysis_means = jnp.mean(ensemble_analysis, axis=2)\n",
        "\n",
        "    file = f\"ACM270_Model_Error/long_training_data_noise_{noise_const}_dt_{dt}.npz\"\n",
        "    data = np.load(file)\n",
        "    forecast_state = data[\"forecast\"]\n",
        "    analysis_state = data[\"analysis\"]\n",
        "\n",
        "    key = jax.random.PRNGKey(0)\n",
        "    input_shape = (K,)\n",
        "    features = K\n",
        "    model, params = create_model(key, input_shape, features)\n",
        "\n",
        "    learning_rate = 1e-3\n",
        "    optimizer = optax.adam(learning_rate)\n",
        "    state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=optimizer)\n",
        "\n",
        "    num_epochs = train_epoch\n",
        "    _,_,n = forecast_state.shape\n",
        "    for i in range(50):\n",
        "      forecast_means = forecast_state[:,:,i]\n",
        "      analysis_means = analysis_state[:,:,i]\n",
        "      state = train_nn(state, forecast_means, analysis_means, num_epochs=num_epochs)\n",
        "\n",
        "    #@partial(jax.jit, static_argnums=(3))\n",
        "    def ensrf_steps_nn(state_transition_function, n_ensemble, ensemble_init, num_steps, observations, observation_interval, H, Q, R, key, nn_params, model):\n",
        "        def corrected_state_transition(v):\n",
        "            transition = state_transition_function(v)\n",
        "            correction = model.apply({'params': nn_params}, transition)\n",
        "            return transition + correction\n",
        "\n",
        "        model_vmap = jax.vmap(corrected_state_transition, in_axes=1, out_axes=1)\n",
        "        key, *subkeys = jax.random.split(key, num=num_steps + 1)\n",
        "        subkeys = jnp.array(subkeys)\n",
        "\n",
        "        def inner(carry, t):\n",
        "            ensemble, covar = carry\n",
        "            ensemble_predicted = model_vmap(ensemble)\n",
        "            _, C_forecast, ensemble_analysis, C_analysis = ensrf_step(ensemble_predicted, observations[t, :], H, Q, R, subkeys[t])\n",
        "            return (ensemble_analysis, C_analysis), (ensemble_predicted, C_forecast, ensemble_analysis, C_analysis)\n",
        "\n",
        "        n = len(Q[0])\n",
        "        covariance_init = jnp.zeros((n, n))\n",
        "        _, (ensemble_forecast, C_forecast, ensemble_analysis, C_analysis) = jax.lax.scan(inner, (ensemble_init, covariance_init), jnp.arange(num_steps))\n",
        "\n",
        "        return ensemble_forecast, C_forecast, ensemble_analysis, C_analysis\n",
        "\n",
        "    file = f\"ACM270_Model_Error/testing_data_noise_{noise_const}_dt_{dt}.npz\"\n",
        "    data = np.load(file)\n",
        "    noisy_trajectory = data[\"noisy_trajectory\"]\n",
        "    try:\n",
        "      trajectory=data['true_trajectory']\n",
        "    except:\n",
        "      trajectory=data['trajectory']\n",
        "\n",
        "    noisy_trajectory =  jnp.asarray(noisy_trajectory)\n",
        "    trajectory = jnp.asarray(trajectory)\n",
        "\n",
        "    NRMSE_fm = []\n",
        "    NRMSE_as = []\n",
        "    NRMSE_fm_NN = []\n",
        "    NRMSE_as_NN = []\n",
        "\n",
        "    _,_,n = noisy_trajectory.shape\n",
        "\n",
        "    for i in range(n):\n",
        "      observations = noisy_trajectory[:,:,i]\n",
        "\n",
        "      nn_params = state.params\n",
        "      ensemble_forecast_NN, C_forecast_NN, ensemble_analysis_NN, C_analysis_NN = ensrf_steps_nn(\n",
        "          lorenz1,\n",
        "          n_ensemble,\n",
        "          ensemble_init,\n",
        "          time_steps,\n",
        "          observations,\n",
        "          1,\n",
        "          H,\n",
        "          Q,\n",
        "          R,\n",
        "          key,\n",
        "          nn_params,\n",
        "          model\n",
        "      )\n",
        "\n",
        "      ensemble_forecast, C_forecast, ensemble_analysis, C_analysis = ensrf_steps(\n",
        "          lorenz1,\n",
        "          n_ensemble,\n",
        "          ensemble_init,\n",
        "          time_steps,\n",
        "          observations,\n",
        "          1,\n",
        "          H,\n",
        "          Q,\n",
        "          R,\n",
        "          key\n",
        "      )\n",
        "\n",
        "      time_steps = ensemble_forecast.shape[0]\n",
        "      time = jnp.arange(time_steps)\n",
        "\n",
        "      true_states = trajectory[:,:,i]\n",
        "      forecast_means = jnp.mean(ensemble_forecast, axis=2)\n",
        "      analysis_means = jnp.mean(ensemble_analysis, axis=2)\n",
        "\n",
        "      forecast_means_NN = jnp.mean(ensemble_forecast_NN, axis=2)\n",
        "      analysis_means_NN = jnp.mean(ensemble_analysis_NN, axis=2)\n",
        "\n",
        "      model_error = true_states - forecast_means\n",
        "      NRMSE_fm.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "      model_error = true_states - analysis_means\n",
        "      NRMSE_as.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "      model_error = true_states - forecast_means_NN\n",
        "      NRMSE_fm_NN.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "      model_error = true_states - analysis_means_NN\n",
        "      NRMSE_as_NN.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "\n",
        "    full_NRMSE_fm.append(np.mean(NRMSE_fm))\n",
        "    full_NRMSE_as.append(np.mean(NRMSE_as))\n",
        "    full_NRMSE_fm_NN.append(np.mean(NRMSE_fm_NN))\n",
        "    full_NRMSE_as_NN.append(np.mean(NRMSE_as_NN))\n",
        "\n",
        "fontsize = 20\n",
        "res = 500\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(epochs, full_NRMSE_as, label=\"Analysis (uncorrected)\", linestyle=\"-\",color='k', linewidth=2.5,markersize=7)\n",
        "plt.plot(epochs, full_NRMSE_as_NN, label=\"Analysis (corrected)\", linestyle=\"-\", marker=\"o\",color='b', linewidth=2.5,markersize=7)\n",
        "plt.plot(epochs, full_NRMSE_fm, label=\"Forecast (uncorrected)\", linestyle=\"--\",color='k', linewidth=7)\n",
        "plt.plot(epochs, full_NRMSE_fm_NN, label=\"Forecast (corrected)\", linestyle=\"--\", marker=\"x\",color='b', linewidth=2.5,markersize=7)\n",
        "\n",
        "plt.xlabel(\"Number of Epochs\",fontsize=fontsize)\n",
        "plt.ylabel(\"Total NRMSE\",fontsize=fontsize)\n",
        "plt.title(\"Total NRMSE vs Epochs\",fontsize=fontsize)\n",
        "plt.legend(fontsize=fontsize/1.25)\n",
        "plt.grid(True)\n",
        "plt.xticks(fontsize=fontsize / 1.25)\n",
        "plt.yticks(fontsize=fontsize / 1.25)\n",
        "plt.savefig(f\"MSE_vs_epoch_noise_{noise_const}_dt_{dt}.png\", bbox_inches=\"tight\", dpi=res)\n"
      ],
      "metadata": {
        "id": "FoIv9gjJpku-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MSE vs. learning rate"
      ],
      "metadata": {
        "id": "8typ4CFZ3Abw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "!pip install filterpy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "from filterpy.kalman import EnsembleKalmanFilter as EnKF\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.integrate as integrate\n",
        "from scipy.interpolate import griddata\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "import optax\n",
        "from jax import jit, random, lax\n",
        "from jax.scipy.linalg import sqrtm\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import integrate\n",
        "from jax.tree_util import Partial\n",
        "from functools import partial\n",
        "\n",
        "! rm -rf ACM270_Model_Error\n",
        "# if os.path.isdir('./ACM270_Model_Error/') == False:\n",
        "! git clone https://github.com/sreemanti-dey/ACM270_Model_Error.git\n",
        "sys.path.append('./ACM270_Model_Error/')\n",
        "\n",
        "! cd ACM270_Model_Error\n",
        "\n",
        "\"\"\"# True Trajectory and Noisy Observations with 2-Scale Lorenz96\"\"\"\n",
        "for iii in range(2):\n",
        "  if iii == 0:\n",
        "      # parameters for two-scale L96\n",
        "      K = 36                      # number of large scale vars\n",
        "      J = 10                      # number of small scale vars per large var\n",
        "      h = 0.25                   # part of coupling\n",
        "      c = 10                     # part of coupling\n",
        "      b = 10                     # part of coupling\n",
        "      F = 10                     # forcing\n",
        "      dt = 0.1                  # time step\n",
        "      noise_const = 0.1\n",
        "      num_steps = 200\n",
        "      num_steps = int(num_steps * (0.05 / dt))\n",
        "      time_steps = num_steps\n",
        "  else:\n",
        "      # parameters for two-scale L96\n",
        "      K = 36                      # number of large scale vars\n",
        "      J = 10                      # number of small scale vars per large var\n",
        "      h = 0.25                   # part of coupling\n",
        "      c = 10                     # part of coupling\n",
        "      b = 10                     # part of coupling\n",
        "      F = 10                     # forcing\n",
        "      dt = 0.05                  # time step\n",
        "      noise_const = 0.1\n",
        "      num_steps = 200\n",
        "      num_steps = int(num_steps * (0.05 / dt))\n",
        "      time_steps = num_steps\n",
        "  full_NRMSE_fm = []\n",
        "  full_NRMSE_as = []\n",
        "  full_NRMSE_fm_NN = []\n",
        "  full_NRMSE_as_NN = []\n",
        "\n",
        "  LRs = np.logspace(-5,-1,15)\n",
        "\n",
        "  for idx_n, LR in enumerate(LRs):\n",
        "      @jit\n",
        "      def L96_2(xy):\n",
        "          x = xy[0:K]\n",
        "          y = xy[K:].reshape(K, J)\n",
        "\n",
        "          dx = jnp.zeros(K)\n",
        "          dy = jnp.zeros((K, J))\n",
        "\n",
        "          for k in range(K):\n",
        "              dxdt = -1 * x[k - 1] * (x[k - 2] - x[(k + 1) % K]) - x[k] + F - (h * c / b) * jnp.sum(y[k])\n",
        "              dx = dx.at[k].set(dxdt)\n",
        "\n",
        "              for j in range(J):\n",
        "                  dydt = -1 * c * b * y[k, (j + 1) % J] * (y[k, (j + 2) % J] - y[k, j - 1]) - c * y[k, j] + (h * c / b) * x[k]\n",
        "                  dy = dy.at[k, j].set(dydt)\n",
        "\n",
        "          return jnp.concatenate([dx, dy.flatten()])\n",
        "\n",
        "      @jit\n",
        "      def rk4_step_lorenz96_2(x):\n",
        "          f = lambda y: L96_2(y)\n",
        "          k1 = dt * f(x)\n",
        "          k2 = dt * f(x + k1/2)\n",
        "          k3 = dt * f(x + k2/2)\n",
        "          k4 = dt * f(x + k3)\n",
        "          return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "      keys = iter(random.split(random.PRNGKey(0), 10))\n",
        "      key = random.PRNGKey(0)\n",
        "      # randomized starting point for large scale, 0 for small scale\n",
        "      x0 = np.linspace(0, 1, K)  # np.random.rand(K)\n",
        "      y0 = np.zeros((K, J))\n",
        "      xy0 = np.concatenate([x0, y0.flatten()])\n",
        "\n",
        "      rk4_step_lorenz96_2(xy0)\n",
        "\n",
        "      trajectory = jnp.zeros((time_steps, len(xy0)))\n",
        "      noisy_obs = jnp.zeros((time_steps, len(xy0)))\n",
        "      noise_covar = jnp.eye(len(xy0)) * noise_const\n",
        "\n",
        "      xy = xy0\n",
        "      for i in tqdm(range(time_steps)):\n",
        "          xy = rk4_step_lorenz96_2(xy)\n",
        "          trajectory = trajectory.at[i].set(xy)\n",
        "          # Add noise to the observations\n",
        "          noise = random.multivariate_normal(key, jnp.zeros(len(xy0)), noise_covar)\n",
        "          noisy_obs = noisy_obs.at[i].set(xy + noise)\n",
        "          key, _ = random.split(key)  # Update key for the next iteration\n",
        "\n",
        "      \"\"\"## True Trajectory\n",
        "\n",
        "      ## Noisy Observations\n",
        "      \"\"\"\n",
        "\n",
        "      true_states = trajectory\n",
        "\n",
        "      \"\"\"# EnKF for 1-Scale Assimilation\"\"\"\n",
        "\n",
        "      @jit\n",
        "      def rk4_step_lorenz96_1(x):\n",
        "          f = lambda y: (jnp.roll(y, 1) - jnp.roll(y, -2)) * jnp.roll(y, -1) - y + F\n",
        "          k1 = dt * f(x)\n",
        "          k2 = dt * f(x + k1/2)\n",
        "          k3 = dt * f(x + k2/2)\n",
        "          k4 = dt * f(x + k3)\n",
        "          return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "      lorenz1 = Partial(rk4_step_lorenz96_1)\n",
        "      lorenz2 = Partial(rk4_step_lorenz96_2)\n",
        "\n",
        "      @jit\n",
        "      def ledoit_wolf(P, shrinkage):\n",
        "          return (1 - shrinkage) * P + shrinkage * jnp.trace(P) / P.shape[0] * jnp.eye(P.shape[0])\n",
        "\n",
        "      @jit\n",
        "      def ensrf_step(ensemble, y, H, Q, R, key, inflation = 1.2):\n",
        "          n_ensemble = ensemble.shape[1]\n",
        "          x_m = jnp.mean(ensemble, axis=1)\n",
        "          A = ensemble - x_m.reshape((-1, 1))\n",
        "          C_pred = (A @ A.T) / (n_ensemble - 1) + Q\n",
        "          C_pred = ledoit_wolf(C_pred, noise_const)\n",
        "          A = A * inflation\n",
        "          P =  (A @ A.T) / (n_ensemble - 1) + Q\n",
        "          K = P @ H.T @ jnp.linalg.inv(H @ P @ H.T + R)\n",
        "          x_m += K @ (y - H @ x_m)\n",
        "          M_sqrt = sqrt_m(jnp.eye(x_m.shape[0]) - K @ H)\n",
        "          updated_A = M_sqrt @ A\n",
        "          updated_ensemble = x_m.reshape((-1, 1)) + updated_A\n",
        "          updated_P = (updated_A @ updated_A.T) / (n_ensemble - 1)\n",
        "          updated_P = ledoit_wolf(updated_P, noise_const)\n",
        "\n",
        "          ensemble = ensemble.astype(jnp.float32)\n",
        "          C_pred = C_pred.astype(jnp.float32)\n",
        "          updated_ensemble = updated_ensemble.astype(jnp.float32)\n",
        "          updated_P = updated_P.astype(jnp.float32)\n",
        "          return ensemble, C_pred, updated_ensemble, updated_P\n",
        "\n",
        "      @jit\n",
        "      def sqrt_m(M):\n",
        "          eigenvalues, eigenvectors = jnp.linalg.eigh(M)\n",
        "          inv_sqrt_eigenvalues = jnp.sqrt(eigenvalues)\n",
        "          Lambda_inv_sqrt = jnp.diag(inv_sqrt_eigenvalues)\n",
        "          M_sqrt = eigenvectors @ Lambda_inv_sqrt @ eigenvectors.T\n",
        "          return M_sqrt.real\n",
        "\n",
        "      @partial(jit, static_argnums=(3))\n",
        "      def ensrf_steps(state_transition_function, n_ensemble, ensemble_init, num_steps, observations, observation_interval, H, Q, R, key):\n",
        "          model_vmap = jax.vmap(lambda v: state_transition_function(v), in_axes=1, out_axes=1)\n",
        "          key, *subkeys = random.split(key, num=num_steps + 1)\n",
        "          subkeys = jnp.array(subkeys)\n",
        "\n",
        "          def inner(carry, t):\n",
        "              ensemble, covar = carry\n",
        "              ensemble_predicted = model_vmap(ensemble)\n",
        "              _, C_forecast, ensemble_analysis, C_analysis = ensrf_step(ensemble_predicted, observations[t, :], H, Q, R, subkeys[t])\n",
        "              return (ensemble_analysis, C_analysis), (ensemble_predicted, C_forecast, ensemble_analysis, C_analysis)\n",
        "\n",
        "          n = len(Q[0])\n",
        "          covariance_init = jnp.zeros((n, n))\n",
        "          _, (ensemble_forecast, C_forecast, ensemble_analysis, C_analysis) = jax.lax.scan(inner, (ensemble_init, covariance_init), jnp.arange(num_steps))\n",
        "\n",
        "          return ensemble_forecast, C_forecast, ensemble_analysis, C_analysis\n",
        "\n",
        "      class IncrementCorrectionModel(nn.Module):\n",
        "          features: int\n",
        "\n",
        "          @nn.compact\n",
        "          def __call__(self, x):\n",
        "              x = nn.Dense(self.features)(x)\n",
        "              x = nn.relu(x)\n",
        "              x = nn.Dense(self.features)(x)\n",
        "              x = nn.relu(x)\n",
        "              x = nn.Dense(self.features)(x)\n",
        "              x = nn.relu(x)\n",
        "              x = nn.Dense(x.shape[-1])(x)  # Output layer should match input dimension\n",
        "              return x\n",
        "\n",
        "      def create_model(key, input_shape, features):\n",
        "          model = IncrementCorrectionModel(features)\n",
        "          params = model.init(key, jnp.ones(input_shape))['params']\n",
        "          return model, params\n",
        "\n",
        "      def loss_fn(params, apply_fn, x, y):\n",
        "          predictions = apply_fn({'params': params}, x)\n",
        "          loss = jnp.mean((predictions - y) ** 2)\n",
        "          return loss\n",
        "\n",
        "      @jax.jit\n",
        "      def train_step(state, forecast_states, increments):\n",
        "          def loss_fn_wrapper(params):\n",
        "              return loss_fn(params, state.apply_fn, forecast_states, increments)\n",
        "\n",
        "          grads = jax.grad(loss_fn_wrapper)(state.params)\n",
        "          state = state.apply_gradients(grads=grads)\n",
        "          return state\n",
        "\n",
        "      def train_nn(state, forecast_states, analysis_states, num_epochs=10):\n",
        "          increments = analysis_states - forecast_states\n",
        "\n",
        "          for epoch in range(num_epochs):\n",
        "              state = train_step(state, forecast_states, increments)\n",
        "              current_loss = loss_fn(state.params, state.apply_fn, forecast_states, increments)\n",
        "              print(f'Epoch {epoch+1}, Loss: {current_loss}')\n",
        "\n",
        "          return state\n",
        "\n",
        "      Q = noise_const * jnp.eye(K)\n",
        "      H = jnp.eye(K)\n",
        "      R = jnp.eye(K) * noise_const\n",
        "      n_ensemble = 10\n",
        "      num_steps = time_steps\n",
        "      #the ensrf (ENKF) will run single scale Lorenz on the first K variables\n",
        "      observations = noisy_obs[:,:K]\n",
        "      initial_state = np.zeros((1, K))\n",
        "      ensemble_init = random.multivariate_normal(key, initial_state, Q, (n_ensemble,)).T\n",
        "      ensemble_forecast, C_forecast, ensemble_analysis, C_analysis = ensrf_steps(lorenz1, n_ensemble, ensemble_init, time_steps, observations, 1, H, Q, R, key)\n",
        "\n",
        "      time_steps = ensemble_forecast.shape[0]\n",
        "      time = jnp.arange(time_steps)\n",
        "\n",
        "      forecast_means = jnp.mean(ensemble_forecast, axis=2)\n",
        "      analysis_means = jnp.mean(ensemble_analysis, axis=2)\n",
        "\n",
        "      file = f\"ACM270_Model_Error/long_training_data_noise_{noise_const}_dt_{dt}.npz\"\n",
        "      data = np.load(file)\n",
        "      forecast_state = data[\"forecast\"]\n",
        "      analysis_state = data[\"analysis\"]\n",
        "\n",
        "      key = jax.random.PRNGKey(0)\n",
        "      input_shape = (K,)\n",
        "      features = K\n",
        "      model, params = create_model(key, input_shape, features)\n",
        "\n",
        "      learning_rate = LR\n",
        "      optimizer = optax.adam(learning_rate)\n",
        "      state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=optimizer)\n",
        "\n",
        "      num_epochs = 15\n",
        "      _,_,n = forecast_state.shape\n",
        "      for i in range(50):\n",
        "        forecast_means = forecast_state[:,:,i]\n",
        "        analysis_means = analysis_state[:,:,i]\n",
        "        state = train_nn(state, forecast_means, analysis_means, num_epochs=num_epochs)\n",
        "\n",
        "      #@partial(jax.jit, static_argnums=(3))\n",
        "      def ensrf_steps_nn(state_transition_function, n_ensemble, ensemble_init, num_steps, observations, observation_interval, H, Q, R, key, nn_params, model):\n",
        "          def corrected_state_transition(v):\n",
        "              transition = state_transition_function(v)\n",
        "              correction = model.apply({'params': nn_params}, transition)\n",
        "              return transition + correction\n",
        "\n",
        "          model_vmap = jax.vmap(corrected_state_transition, in_axes=1, out_axes=1)\n",
        "          key, *subkeys = jax.random.split(key, num=num_steps + 1)\n",
        "          subkeys = jnp.array(subkeys)\n",
        "\n",
        "          def inner(carry, t):\n",
        "              ensemble, covar = carry\n",
        "              ensemble_predicted = model_vmap(ensemble)\n",
        "              _, C_forecast, ensemble_analysis, C_analysis = ensrf_step(ensemble_predicted, observations[t, :], H, Q, R, subkeys[t])\n",
        "              return (ensemble_analysis, C_analysis), (ensemble_predicted, C_forecast, ensemble_analysis, C_analysis)\n",
        "\n",
        "          n = len(Q[0])\n",
        "          covariance_init = jnp.zeros((n, n))\n",
        "          _, (ensemble_forecast, C_forecast, ensemble_analysis, C_analysis) = jax.lax.scan(inner, (ensemble_init, covariance_init), jnp.arange(num_steps))\n",
        "\n",
        "          return ensemble_forecast, C_forecast, ensemble_analysis, C_analysis\n",
        "\n",
        "      file = f\"ACM270_Model_Error/testing_data_noise_{noise_const}_dt_{dt}.npz\"\n",
        "      data = np.load(file)\n",
        "      noisy_trajectory = data[\"noisy_trajectory\"]\n",
        "      try:\n",
        "        trajectory=data['true_trajectory']\n",
        "      except:\n",
        "        trajectory=data['trajectory']\n",
        "\n",
        "      noisy_trajectory =  jnp.asarray(noisy_trajectory)\n",
        "      trajectory = jnp.asarray(trajectory)\n",
        "\n",
        "      NRMSE_fm = []\n",
        "      NRMSE_as = []\n",
        "      NRMSE_fm_NN = []\n",
        "      NRMSE_as_NN = []\n",
        "\n",
        "      _,_,n = noisy_trajectory.shape\n",
        "\n",
        "      for i in range(n):\n",
        "        observations = noisy_trajectory[:,:,i]\n",
        "\n",
        "        nn_params = state.params\n",
        "        ensemble_forecast_NN, C_forecast_NN, ensemble_analysis_NN, C_analysis_NN = ensrf_steps_nn(\n",
        "            lorenz1,\n",
        "            n_ensemble,\n",
        "            ensemble_init,\n",
        "            time_steps,\n",
        "            observations,\n",
        "            1,\n",
        "            H,\n",
        "            Q,\n",
        "            R,\n",
        "            key,\n",
        "            nn_params,\n",
        "            model\n",
        "        )\n",
        "\n",
        "        ensemble_forecast, C_forecast, ensemble_analysis, C_analysis = ensrf_steps(\n",
        "            lorenz1,\n",
        "            n_ensemble,\n",
        "            ensemble_init,\n",
        "            time_steps,\n",
        "            observations,\n",
        "            1,\n",
        "            H,\n",
        "            Q,\n",
        "            R,\n",
        "            key\n",
        "        )\n",
        "\n",
        "        time_steps = ensemble_forecast.shape[0]\n",
        "        time = jnp.arange(time_steps)\n",
        "\n",
        "        true_states = trajectory[:,:,i]\n",
        "        forecast_means = jnp.mean(ensemble_forecast, axis=2)\n",
        "        analysis_means = jnp.mean(ensemble_analysis, axis=2)\n",
        "\n",
        "        forecast_means_NN = jnp.mean(ensemble_forecast_NN, axis=2)\n",
        "        analysis_means_NN = jnp.mean(ensemble_analysis_NN, axis=2)\n",
        "\n",
        "        model_error = true_states - forecast_means\n",
        "        NRMSE_fm.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "        model_error = true_states - analysis_means\n",
        "        NRMSE_as.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "        model_error = true_states - forecast_means_NN\n",
        "        NRMSE_fm_NN.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "        model_error = true_states - analysis_means_NN\n",
        "        NRMSE_as_NN.append(np.dot(model_error.flatten(), model_error.flatten()) / np.dot(true_states.flatten(), true_states.flatten()))\n",
        "\n",
        "      full_NRMSE_fm.append(np.mean(NRMSE_fm))\n",
        "      full_NRMSE_as.append(np.mean(NRMSE_as))\n",
        "      full_NRMSE_fm_NN.append(np.mean(NRMSE_fm_NN))\n",
        "      full_NRMSE_as_NN.append(np.mean(NRMSE_as_NN))\n",
        "\n",
        "  fontsize = 20\n",
        "  res = 500\n",
        "\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.semilogx(LRs, full_NRMSE_as, label=\"Analysis (uncorrected)\", linestyle=\"-\",color='k', linewidth=2.5,markersize=2)\n",
        "  plt.semilogx(LRs, full_NRMSE_as_NN, label=\"Analysis (corrected)\", linestyle=\"-\", marker=\"o\",color='b', linewidth=2.5,markersize=7)\n",
        "  plt.semilogx(LRs, full_NRMSE_fm, label=\"Forecast (uncorrected)\", linestyle=\"--\",color='k', linewidth=2.5,markersize=7)\n",
        "  plt.semilogx(LRs, full_NRMSE_fm_NN, label=\"Forecast (corrected)\", linestyle=\"--\", marker=\"x\",color='b', linewidth=2.5,markersize=7)\n",
        "\n",
        "  plt.xlabel(\"Learning rate\",fontsize=fontsize)\n",
        "  plt.ylabel(\"Total NRMSE\",fontsize=fontsize)\n",
        "  plt.title(\"Total NRMSE vs learning rate\",fontsize=fontsize)\n",
        "  plt.legend(fontsize=fontsize/1.25)\n",
        "  plt.grid(True)\n",
        "  plt.xticks(fontsize=fontsize / 1.25)\n",
        "  plt.yticks(fontsize=fontsize / 1.25)\n",
        "  plt.savefig(f\"MSE_vs_LR_noise_{noise_const}_dt_{dt}.png\", bbox_inches=\"tight\", dpi=res)\n"
      ],
      "metadata": {
        "id": "EwGAnOEo27SD"
      },
      "execution_count": 21,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}